{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6273598,"sourceType":"datasetVersion","datasetId":3606607},{"sourceId":6484345,"sourceType":"datasetVersion","datasetId":3746621},{"sourceId":6575417,"sourceType":"datasetVersion","datasetId":3797438}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T07:35:22.188951Z","iopub.execute_input":"2023-10-01T07:35:22.189346Z","iopub.status.idle":"2023-10-01T07:35:22.194265Z","shell.execute_reply.started":"2023-10-01T07:35:22.189314Z","shell.execute_reply":"2023-10-01T07:35:22.193142Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n# !pip install xformers\n!pip install Dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:35:22.196077Z","iopub.execute_input":"2023-10-01T07:35:22.196796Z","iopub.status.idle":"2023-10-01T07:35:38.390902Z","shell.execute_reply.started":"2023-10-01T07:35:22.196765Z","shell.execute_reply":"2023-10-01T07:35:38.389720Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\nRequirement already satisfied: Dataset in /opt/conda/lib/python3.10/site-packages (1.6.2)\nRequirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from Dataset) (1.4.49)\nRequirement already satisfied: alembic>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from Dataset) (1.11.1)\nRequirement already satisfied: banal>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from Dataset) (1.0.6)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=0.6.2->Dataset) (1.2.4)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=0.6.2->Dataset) (4.6.3)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<2.0.0,>=1.3.2->Dataset) (2.0.2)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=0.6.2->Dataset) (2.1.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_json(path_or_buf=\"/kaggle/input/indoml-massive-dataset/public_dat/massive_train.data.jsonl\", lines=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:35:38.393179Z","iopub.execute_input":"2023-10-01T07:35:38.393468Z","iopub.status.idle":"2023-10-01T07:35:57.219199Z","shell.execute_reply.started":"2023-10-01T07:35:38.393445Z","shell.execute_reply":"2023-10-01T07:35:57.218258Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:35:57.220725Z","iopub.execute_input":"2023-10-01T07:35:57.221287Z","iopub.status.idle":"2023-10-01T07:35:57.246059Z","shell.execute_reply.started":"2023-10-01T07:35:57.221256Z","shell.execute_reply":"2023-10-01T07:35:57.245191Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  indoml_id  id locale partition scenario  \\\n0   af-ZA|1   1  af-ZA     train    alarm   \n1   af-ZA|2   2  af-ZA     train    alarm   \n2   af-ZA|4   4  af-ZA     train    audio   \n3   af-ZA|5   5  af-ZA     train    audio   \n4   af-ZA|6   6  af-ZA     train    audio   \n\n                                         utt  \\\n0    maak my wakker nege-uur v. m. op vrydag   \n1      stel 'n alarm vir twee ure van nou af   \n2                            janneman stilte   \n3                                       stop   \n4  janneman onderbreek dit vir tien sekondes   \n\n                                           annot_utt  worker_id  \\\n0  maak my wakker [time : nege-uur v. m.] op [dat...         20   \n1     stel 'n alarm vir [time : twee ure van nou af]         20   \n2                                    janneman stilte         40   \n3                                               stop          2   \n4  janneman onderbreek dit vir [time : tien sekon...         40   \n\n                                         slot_method  \\\n0  [{'slot': 'time', 'method': 'translation'}, {'...   \n1        [{'slot': 'time', 'method': 'translation'}]   \n2                                                 []   \n3                                                 []   \n4        [{'slot': 'time', 'method': 'translation'}]   \n\n                                           judgments  \n0  [{'worker_id': '40', 'intent_score': 1, 'slots...  \n1  [{'worker_id': '64', 'intent_score': 1, 'slots...  \n2  [{'worker_id': '45', 'intent_score': 1, 'slots...  \n3  [{'worker_id': '49', 'intent_score': 1, 'slots...  \n4  [{'worker_id': '45', 'intent_score': 1, 'slots...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>indoml_id</th>\n      <th>id</th>\n      <th>locale</th>\n      <th>partition</th>\n      <th>scenario</th>\n      <th>utt</th>\n      <th>annot_utt</th>\n      <th>worker_id</th>\n      <th>slot_method</th>\n      <th>judgments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>af-ZA|1</td>\n      <td>1</td>\n      <td>af-ZA</td>\n      <td>train</td>\n      <td>alarm</td>\n      <td>maak my wakker nege-uur v. m. op vrydag</td>\n      <td>maak my wakker [time : nege-uur v. m.] op [dat...</td>\n      <td>20</td>\n      <td>[{'slot': 'time', 'method': 'translation'}, {'...</td>\n      <td>[{'worker_id': '40', 'intent_score': 1, 'slots...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>af-ZA|2</td>\n      <td>2</td>\n      <td>af-ZA</td>\n      <td>train</td>\n      <td>alarm</td>\n      <td>stel 'n alarm vir twee ure van nou af</td>\n      <td>stel 'n alarm vir [time : twee ure van nou af]</td>\n      <td>20</td>\n      <td>[{'slot': 'time', 'method': 'translation'}]</td>\n      <td>[{'worker_id': '64', 'intent_score': 1, 'slots...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>af-ZA|4</td>\n      <td>4</td>\n      <td>af-ZA</td>\n      <td>train</td>\n      <td>audio</td>\n      <td>janneman stilte</td>\n      <td>janneman stilte</td>\n      <td>40</td>\n      <td>[]</td>\n      <td>[{'worker_id': '45', 'intent_score': 1, 'slots...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>af-ZA|5</td>\n      <td>5</td>\n      <td>af-ZA</td>\n      <td>train</td>\n      <td>audio</td>\n      <td>stop</td>\n      <td>stop</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>[{'worker_id': '49', 'intent_score': 1, 'slots...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>af-ZA|6</td>\n      <td>6</td>\n      <td>af-ZA</td>\n      <td>train</td>\n      <td>audio</td>\n      <td>janneman onderbreek dit vir tien sekondes</td>\n      <td>janneman onderbreek dit vir [time : tien sekon...</td>\n      <td>40</td>\n      <td>[{'slot': 'time', 'method': 'translation'}]</td>\n      <td>[{'worker_id': '45', 'intent_score': 1, 'slots...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.system('pip install accelerate tasknet tasksource')\nimport tasknet as tn\nfrom datasets import load_dataset\nimport datasets","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-10-01T07:35:57.248698Z","iopub.execute_input":"2023-10-01T07:35:57.249023Z","iopub.status.idle":"2023-10-01T07:36:27.251834Z","shell.execute_reply.started":"2023-10-01T07:35:57.248991Z","shell.execute_reply":"2023-10-01T07:36:27.250734Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.20.3)\nCollecting tasknet\n  Downloading tasknet-1.49.0-py3-none-any.whl (28 kB)\nCollecting tasksource\n  Downloading tasksource-0.0.40-py3-none-any.whl (42 kB)\n\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.9/42.9 kB 3.7 MB/s eta 0:00:00\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from tasknet) (4.30.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from tasknet) (2.1.0)\nCollecting evaluate (from tasknet)\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.4/81.4 kB 5.6 MB/s eta 0:00:00\n\u001b[?25hCollecting lazy-load (from tasknet)\n  Downloading lazy_load-0.8.3-py3-none-any.whl (7.1 kB)\nRequirement already satisfied: easydict in /opt/conda/lib/python3.10/site-packages (from tasknet) (1.10)\nRequirement already satisfied: frozendict in /opt/conda/lib/python3.10/site-packages (from tasknet) (2.3.8)\nRequirement already satisfied: funcy in /opt/conda/lib/python3.10/site-packages (from tasknet) (2.0)\nCollecting seqeval (from tasknet)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 3.7 MB/s eta 0:00:00\n\u001b[?25h  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting magicattr (from tasknet)\n  Downloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from tasknet) (0.1.99)\nCollecting dotwiz (from tasksource)\n  Downloading dotwiz-0.4.0-py2.py3-none-any.whl (13 kB)\nCollecting exrex (from tasksource)\n  Downloading exrex-0.11.0-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from tasksource) (1.5.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from tasksource) (1.11.1)\nCollecting sorcery (from tasksource)\n  Downloading sorcery-0.2.2-py3-none-any.whl (16 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->tasknet) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->tasknet) (0.3.6)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets->tasknet) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets->tasknet) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->tasknet) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->tasknet) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->tasknet) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->tasknet) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets->tasknet) (0.16.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->tasknet) (0.18.0)\nCollecting pyheck==0.1.5 (from dotwiz->tasksource)\n  Downloading pyheck-0.1.5-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 32.2 MB/s eta 0:00:00\n\u001b[?25hRequirement already satisfied: lazy-object-proxy>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from lazy-load->tasknet) (1.9.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->tasksource) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->tasksource) (2023.3)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval->tasknet) (1.2.2)\nRequirement already satisfied: executing in /opt/conda/lib/python3.10/site-packages (from sorcery->tasksource) (1.2.0)\nCollecting littleutils>=0.2.1 (from sorcery->tasksource)\n  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: asttokens in /opt/conda/lib/python3.10/site-packages (from sorcery->tasksource) (2.2.1)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from sorcery->tasksource) (1.14.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->tasknet) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->tasknet) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers->tasknet) (0.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->tasknet) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->tasknet) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->tasknet) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->tasknet) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->tasknet) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->tasknet) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->tasknet) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->tasksource) (1.16.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->tasknet) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->tasknet) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->tasknet) (2023.5.7)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tasknet) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tasknet) (3.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\nBuilding wheels for collected packages: seqeval, littleutils\n  Building wheel for seqeval (setup.py): started\n  Building wheel for seqeval (setup.py): finished with status 'done'\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=82ee1ec0ecf79d1b619f9271e64c02c6cb9516c33d5fa68910478e4a6bc23bda\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n  Building wheel for littleutils (setup.py): started\n  Building wheel for littleutils (setup.py): finished with status 'done'\n  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=fd14334812d2aebfc6e4c098d62eb2e99769af256e01e6e879e850279aeafd29\n  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\nSuccessfully built seqeval littleutils\nInstalling collected packages: magicattr, littleutils, exrex, pyheck, lazy-load, sorcery, dotwiz, seqeval, tasksource, evaluate, tasknet\nSuccessfully installed dotwiz-0.4.0 evaluate-0.4.0 exrex-0.11.0 lazy-load-0.8.3 littleutils-0.2.2 magicattr-0.1.6 pyheck-0.1.5 seqeval-1.2.2 sorcery-0.2.2 tasknet-1.49.0 tasksource-0.0.40\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de574834dfad44d4b54f3987e6e80dfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0a16ef57b4140298112b64fa8bdd805"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a7aab590d5d4b5e9512a43f342749b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"469f0b3a93d64faeafa730c69e304780"}},"metadata":{}}]},{"cell_type":"code","source":"import re\ndef get_tokens_with_entities(raw_text: str):\n    # split the text by spaces only if the space does not occur between square brackets\n    # we do not want to split \"multi-word\" entity value yet\n    raw_tokens = re.split(r\"\\s(?![^\\[]*\\])\", raw_text)\n    # a regex for matching the annotation according to our notation [entity_value](entity_name)\n    entity_value_pattern = r\"\\[(?P<entity>[^:]+?): (?P<value>.+?)\\]\"\n    entity_value_pattern_compiled = re.compile(entity_value_pattern, flags=re.I|re.M)\n\n    tokens_with_entities = []\n\n    for raw_token in raw_tokens:\n        match = entity_value_pattern_compiled.match(raw_token)\n        if match:\n            raw_entity_name, raw_entity_value = match.group(\"entity\"), match.group(\"value\")\n\n            # we prefix the name of entity differently\n            # B- indicates beginning of an entity\n            # I- indicates the token is not a new entity itself but rather a part of existing one\n            for i, raw_entity_token in enumerate(re.split(\"\\s\", raw_entity_value)):\n                entity_prefix = \"B\" if i == 0 else \"I\"\n                entity_name = f\"{entity_prefix}-{raw_entity_name}\"\n                tokens_with_entities.append((raw_entity_token, entity_name))\n        else:\n            tokens_with_entities.append((raw_token, \"O\"))\n\n    return tokens_with_entities\n\nclass NERDataMaker:\n    def __init__(self, texts):\n        self.unique_entities = []\n        self.processed_texts = []\n\n        temp_processed_texts = []\n        for text in texts:\n            tokens_with_entities = get_tokens_with_entities(text)\n            for _, ent in tokens_with_entities:\n                if ent not in self.unique_entities:\n                    self.unique_entities.append(ent)\n            temp_processed_texts.append(tokens_with_entities)\n\n        self.unique_entities.sort(key=lambda ent: ent if ent != \"O\" else \"\")\n\n        for tokens_with_entities in temp_processed_texts:\n            self.processed_texts.append([(t, self.unique_entities.index(ent)) for t, ent in tokens_with_entities])\n\n    @property\n    def id2label(self):\n        return dict(enumerate(self.unique_entities))\n\n    @property\n    def label2id(self):\n        return {v:k for k, v in self.id2label.items()}\n\n    def __len__(self):\n        return len(self.processed_texts)\n    def num_labels(self): \n        return len(self.unique_entities)\n\n    def __getitem__(self, idx):\n        def _process_tokens_for_one_text(id, tokens_with_encoded_entities):\n            ner_tags = []\n            tokens = []\n            for t, ent in tokens_with_encoded_entities:\n                ner_tags.append(ent)\n                tokens.append(t)\n\n            return {\n                \"id\": id,\n                \"ner_tags\": ner_tags,\n                \"tokens\": tokens\n            }\n\n        tokens_with_encoded_entities = self.processed_texts[idx]\n        if isinstance(idx, int):\n            return _process_tokens_for_one_text(idx, tokens_with_encoded_entities)\n        else:\n            return [_process_tokens_for_one_text(i+idx.start, tee) for i, tee in enumerate(tokens_with_encoded_entities)]\n\n    def as_hf_dataset(self, tokenizer):\n        from datasets import Dataset, Features, Value, ClassLabel, Sequence\n        def tokenize_and_align_labels(examples):\n            tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n\n            labels = []\n            for i, label in enumerate(examples[f\"ner_tags\"]):\n                word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n                previous_word_idx = None\n                label_ids = []\n                for word_idx in word_ids:  # Set the special tokens to -100.\n                    if word_idx is None:\n                        label_ids.append(-100)\n                    elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n                        label_ids.append(label[word_idx])\n                    else:\n                        label_ids.append(-100)\n                    previous_word_idx = word_idx\n                labels.append(label_ids)\n\n            tokenized_inputs[\"labels\"] = labels\n            return tokenized_inputs\n\n        ids, ner_tags, tokens = [], [], []\n        for i, pt in enumerate(self.processed_texts):\n            ids.append(i)\n            pt_tokens,pt_tags = list(zip(*pt))\n            ner_tags.append(pt_tags)\n            tokens.append(pt_tokens)\n        data = {\n            \"id\": ids,\n            \"ner_tags\": ner_tags,\n            \"tokens\": tokens\n        }\n        features = Features({\n            \"tokens\": Sequence(Value(\"string\")),\n            \"ner_tags\": Sequence(ClassLabel(names=dm.unique_entities)),\n            \"id\": Value(\"int32\")\n        })\n        ds = Dataset.from_dict(data, features)\n        tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)\n        return tokenized_ds\n\n# usage\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\ndm = NERDataMaker(data[\"annot_utt\"][0:3].tolist())  \n\n\nprint(data[\"annot_utt\"][0])\nprint(get_tokens_with_entities(data[\"annot_utt\"][0]))\nprint(type(dm[0:]))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:27.253330Z","iopub.execute_input":"2023-10-01T07:36:27.254261Z","iopub.status.idle":"2023-10-01T07:36:28.472136Z","shell.execute_reply.started":"2023-10-01T07:36:27.254227Z","shell.execute_reply":"2023-10-01T07:36:28.471128Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd4f7bd9c7784d989fa8044dde29301a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45486bfc4565445ea815ce7ee697a24d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc40cf1f472c484b87d73601b33bd0a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e348e7b3375c455a959a3e08fdb3caa5"}},"metadata":{}},{"name":"stdout","text":"maak my wakker [time : nege-uur v. m.] op [date : vrydag]\n[('maak', 'O'), ('my', 'O'), ('wakker', 'O'), ('nege-uur', 'B-time '), ('v.', 'I-time '), ('m.', 'I-time '), ('op', 'O'), ('vrydag', 'B-date ')]\n<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"right = pd.read_json(path_or_buf=\"/kaggle/input/indoml-massive-dataset/public_dat/massive_train.solution\", lines=True)\nright.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:28.473467Z","iopub.execute_input":"2023-10-01T07:36:28.474378Z","iopub.status.idle":"2023-10-01T07:36:29.590641Z","shell.execute_reply.started":"2023-10-01T07:36:28.474343Z","shell.execute_reply":"2023-10-01T07:36:29.589702Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  indoml_id             intent\n0   af-ZA|1          alarm_set\n1   af-ZA|2          alarm_set\n2   af-ZA|4  audio_volume_mute\n3   af-ZA|5  audio_volume_mute\n4   af-ZA|6  audio_volume_mute","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>indoml_id</th>\n      <th>intent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>af-ZA|1</td>\n      <td>alarm_set</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>af-ZA|2</td>\n      <td>alarm_set</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>af-ZA|4</td>\n      <td>audio_volume_mute</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>af-ZA|5</td>\n      <td>audio_volume_mute</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>af-ZA|6</td>\n      <td>audio_volume_mute</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"merged_df = data.merge(right[['indoml_id', 'intent']], on='indoml_id', how='inner')\nmerged_df.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:29.591850Z","iopub.execute_input":"2023-10-01T07:36:29.592590Z","iopub.status.idle":"2023-10-01T07:36:30.817065Z","shell.execute_reply.started":"2023-10-01T07:36:29.592557Z","shell.execute_reply":"2023-10-01T07:36:30.816138Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Index(['indoml_id', 'id', 'locale', 'partition', 'scenario', 'utt',\n       'annot_utt', 'worker_id', 'slot_method', 'judgments', 'intent'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"rename_columns = {\"utt\": \"text\", \"intent\": \"labels\"}","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:30.818622Z","iopub.execute_input":"2023-10-01T07:36:30.819313Z","iopub.status.idle":"2023-10-01T07:36:30.823925Z","shell.execute_reply.started":"2023-10-01T07:36:30.819278Z","shell.execute_reply":"2023-10-01T07:36:30.823067Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\ntrain = Dataset.from_pandas(merged_df[['indoml_id','utt', 'intent']])","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:30.825460Z","iopub.execute_input":"2023-10-01T07:36:30.825813Z","iopub.status.idle":"2023-10-01T07:36:31.693593Z","shell.execute_reply.started":"2023-10-01T07:36:30.825783Z","shell.execute_reply":"2023-10-01T07:36:31.692637Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"valid = pd.read_json(path_or_buf=\"/kaggle/input/indoml-massive-dataset/public_dat/massive_valid.data.jsonl\", lines=True)\nright = pd.read_json(path_or_buf=\"/kaggle/input/massive-valid/massive_valid.solution\", lines=True)\nvalid_2 = valid.merge(right[['indoml_id', 'intent']], on='indoml_id', how='inner')\nvalid_2 = Dataset.from_pandas(valid_2[['indoml_id','utt', 'intent']])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:31.697285Z","iopub.execute_input":"2023-10-01T07:36:31.697549Z","iopub.status.idle":"2023-10-01T07:36:34.334774Z","shell.execute_reply.started":"2023-10-01T07:36:31.697528Z","shell.execute_reply":"2023-10-01T07:36:34.333590Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetDict()\ndataset[\"train\"] = train\ndataset[\"validation\"] = valid_2","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:34.336293Z","iopub.execute_input":"2023-10-01T07:36:34.337077Z","iopub.status.idle":"2023-10-01T07:36:34.343009Z","shell.execute_reply.started":"2023-10-01T07:36:34.337040Z","shell.execute_reply":"2023-10-01T07:36:34.341839Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"d = NERDataMaker(data[\"annot_utt\"][0:].tolist())\ntrain_slot = datasets.Dataset.from_pandas(pd.DataFrame(data=d[0:]))\nvalid_slot = datasets.Dataset.from_pandas(pd.DataFrame(data=NERDataMaker(valid[\"annot_utt\"][0:].tolist())[0:]))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:34.344721Z","iopub.execute_input":"2023-10-01T07:36:34.345464Z","iopub.status.idle":"2023-10-01T07:36:56.995232Z","shell.execute_reply.started":"2023-10-01T07:36:34.345429Z","shell.execute_reply":"2023-10-01T07:36:56.994227Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"slot = DatasetDict()\nslot[\"train\"] = train_slot\nslot[\"validation\"] = valid_slot","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:56.999945Z","iopub.execute_input":"2023-10-01T07:36:57.002066Z","iopub.status.idle":"2023-10-01T07:36:57.008146Z","shell.execute_reply.started":"2023-10-01T07:36:57.002032Z","shell.execute_reply":"2023-10-01T07:36:57.007362Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"slot","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:57.012640Z","iopub.execute_input":"2023-10-01T07:36:57.015010Z","iopub.status.idle":"2023-10-01T07:36:57.026185Z","shell.execute_reply.started":"2023-10-01T07:36:57.014978Z","shell.execute_reply":"2023-10-01T07:36:57.025363Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'ner_tags', 'tokens'],\n        num_rows: 587214\n    })\n    validation: Dataset({\n        features: ['id', 'ner_tags', 'tokens'],\n        num_rows: 103683\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"num_labels = len(d.unique_entities)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:57.029360Z","iopub.execute_input":"2023-10-01T07:36:57.030859Z","iopub.status.idle":"2023-10-01T07:36:57.038693Z","shell.execute_reply.started":"2023-10-01T07:36:57.030823Z","shell.execute_reply":"2023-10-01T07:36:57.037833Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Tasknet- multitask traning approach","metadata":{}},{"cell_type":"code","source":"dataset[\"train\"][\"intent\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:57.040276Z","iopub.execute_input":"2023-10-01T07:36:57.041281Z","iopub.status.idle":"2023-10-01T07:36:57.837858Z","shell.execute_reply.started":"2023-10-01T07:36:57.041246Z","shell.execute_reply":"2023-10-01T07:36:57.836936Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'alarm_set'"},"metadata":{}}]},{"cell_type":"code","source":"dataset_target = DatasetDict()\ndataset_target[\"train\"] = dataset[\"train\"].class_encode_column(\"intent\")\nclass_label_feature = dataset_target[\"train\"].features[\"intent\"]\n\ndef map_label2id(example):\n    example['intent'] = class_label_feature.str2int(example['intent'])\n    return example\n\ndataset_target[\"validation\"] = dataset['validation'].map(map_label2id, batched=True)\n\n# dataset_target[\"validation\"] = dataset[\"validation\"].cast_column(\"intent\", class_label_feature)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:36:57.839107Z","iopub.execute_input":"2023-10-01T07:36:57.840140Z","iopub.status.idle":"2023-10-01T07:37:02.827597Z","shell.execute_reply.started":"2023-10-01T07:36:57.840106Z","shell.execute_reply":"2023-10-01T07:37:02.826617Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/588 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e80f3ae15057488187084c6f6fb37160"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/59 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29540038e5704d61ba36d2e545e7166f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/104 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"194233a32c524fe6bbad1b86ad281a50"}},"metadata":{}}]},{"cell_type":"code","source":"class_label_feature","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:37:02.829042Z","iopub.execute_input":"2023-10-01T07:37:02.829969Z","iopub.status.idle":"2023-10-01T07:37:02.836781Z","shell.execute_reply.started":"2023-10-01T07:37:02.829935Z","shell.execute_reply":"2023-10-01T07:37:02.835921Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"ClassLabel(num_classes=60, names=['alarm_query', 'alarm_remove', 'alarm_set', 'audio_volume_down', 'audio_volume_mute', 'audio_volume_other', 'audio_volume_up', 'calendar_query', 'calendar_remove', 'calendar_set', 'cooking_query', 'cooking_recipe', 'datetime_convert', 'datetime_query', 'email_addcontact', 'email_query', 'email_querycontact', 'email_sendemail', 'general_greet', 'general_joke', 'general_quirky', 'iot_cleaning', 'iot_coffee', 'iot_hue_lightchange', 'iot_hue_lightdim', 'iot_hue_lightoff', 'iot_hue_lighton', 'iot_hue_lightup', 'iot_wemo_off', 'iot_wemo_on', 'lists_createoradd', 'lists_query', 'lists_remove', 'music_dislikeness', 'music_likeness', 'music_query', 'music_settings', 'news_query', 'play_audiobook', 'play_game', 'play_music', 'play_podcasts', 'play_radio', 'qa_currency', 'qa_definition', 'qa_factoid', 'qa_maths', 'qa_stock', 'recommendation_events', 'recommendation_locations', 'recommendation_movies', 'social_post', 'social_query', 'takeaway_order', 'takeaway_query', 'transport_query', 'transport_taxi', 'transport_ticket', 'transport_traffic', 'weather_query'], id=None)"},"metadata":{}}]},{"cell_type":"code","source":"dataset_target[\"validation\"][\"intent\"][:10]\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:37:02.837930Z","iopub.execute_input":"2023-10-01T07:37:02.838707Z","iopub.status.idle":"2023-10-01T07:37:02.890006Z","shell.execute_reply.started":"2023-10-01T07:37:02.838674Z","shell.execute_reply":"2023-10-01T07:37:02.889044Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[25, 24, 24, 21, 21, 20, 54, 54, 40, 40]"},"metadata":{}}]},{"cell_type":"code","source":"dataset_target[\"train\"]['intent'][:10]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:37:02.891418Z","iopub.execute_input":"2023-10-01T07:37:02.892022Z","iopub.status.idle":"2023-10-01T07:37:03.091164Z","shell.execute_reply.started":"2023-10-01T07:37:02.891991Z","shell.execute_reply":"2023-10-01T07:37:03.090264Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[2, 2, 4, 4, 4, 4, 23, 23, 25, 25]"},"metadata":{}}]},{"cell_type":"code","source":"slot['test'] = slot['validation'].select(range(1000))\ndataset_target['test'] = dataset_target['validation'].select(range(1000))\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:37:03.092464Z","iopub.execute_input":"2023-10-01T07:37:03.093474Z","iopub.status.idle":"2023-10-01T07:37:03.108818Z","shell.execute_reply.started":"2023-10-01T07:37:03.093442Z","shell.execute_reply":"2023-10-01T07:37:03.108020Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"dataset_target['test'] = dataset_target['test'].rename_column(\"intent\", \"labels\")\ndataset_target['train'] = dataset_target['train'].rename_column(\"intent\", \"labels\")\ndataset_target['validation'] = dataset_target['validation'].rename_column(\"intent\", \"labels\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:37:03.110128Z","iopub.execute_input":"2023-10-01T07:37:03.110798Z","iopub.status.idle":"2023-10-01T07:37:03.123053Z","shell.execute_reply.started":"2023-10-01T07:37:03.110768Z","shell.execute_reply":"2023-10-01T07:37:03.122088Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"slot","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:37:08.984059Z","iopub.execute_input":"2023-10-01T07:37:08.984429Z","iopub.status.idle":"2023-10-01T07:37:08.990727Z","shell.execute_reply.started":"2023-10-01T07:37:08.984400Z","shell.execute_reply":"2023-10-01T07:37:08.989669Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'ner_tags', 'tokens'],\n        num_rows: 587214\n    })\n    validation: Dataset({\n        features: ['id', 'ner_tags', 'tokens'],\n        num_rows: 103683\n    })\n    test: Dataset({\n        features: ['id', 'ner_tags', 'tokens'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"intent_detection = tn.Classification(\n    dataset=dataset_target.shuffle(seed=44).map(batched=True) , s1=\"utt\", y=\"labels\",\n    name = \"intent_classification\",max_rows=100000, max_rows_eval=5000, oversampling=2\n)\n\nslot_detection = tn.TokenClassification(\n    dataset=slot.shuffle(seed=44).map(batched=True), # A dataset string/tuple can also be passed and loaded internally with datasets.load_dataset\n    tokens=\"tokens\", y=\"ner_tags\", num_labels = num_labels,max_rows=10000, max_rows_eval=2000, oversampling=2,\n    name = \"slot_detection\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:37:23.658249Z","iopub.execute_input":"2023-10-01T07:37:23.658584Z","iopub.status.idle":"2023-10-01T07:37:50.829120Z","shell.execute_reply.started":"2023-10-01T07:37:23.658557Z","shell.execute_reply":"2023-10-01T07:37:50.828140Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/588 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e880e809bad84054accddb644546450b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/104 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"171d2d5085214e40b282e333cd2b28e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62b7918691454fa198b5125bd5e02577"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/588 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d01b88fccd5e4c89bf1aa3648959200a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/104 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6ebf19733844c009caf5b09c1a98874"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6afe9c8010a47dba9112321f1666854"}},"metadata":{}}]},{"cell_type":"code","source":"class args:\n    model_name = \"microsoft/mdeberta-v3-base\"\n#     \"bert-base-multilingual-cased\"\n    # remaining arguments are from https://huggingface.co/docs/transformers/v4.24.0/en/main_classes/trainer#transformers.TrainingArguments\n    learning_rate = 1e-5\n    num_train_epochs=6\n    hidden_dropout_prob=0.4\n    attention_probs_dropout_prob = 0.2\n    batch_size=256,\n    add_cln = True\n    load_best_model_at_end=True\n#     evaluation_strategy = \"epoch\"\n    save_strategy = \"epoch\"\n    save_total_limit = 1\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T07:38:37.185615Z","iopub.execute_input":"2023-10-01T07:38:37.186003Z","iopub.status.idle":"2023-10-01T07:38:37.191087Z","shell.execute_reply.started":"2023-10-01T07:38:37.185976Z","shell.execute_reply":"2023-10-01T07:38:37.189702Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"tasks = [intent_detection, slot_detection]\ntz=AutoTokenizer.from_pretrained(\"microsoft/mdeberta-v3-base\")\nmodels = tn.Model(tasks, args) # list of models; by default, shared encoder, task-specific CLS token task-specific head\ntrainer = tn.Trainer(models, tasks, args, tokenizer=tz) # tasks are uniformly sampled by default\ntrainer.train()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-10-01T07:39:29.196041Z","iopub.execute_input":"2023-10-01T07:39:29.196412Z","iopub.status.idle":"2023-10-01T10:57:49.032168Z","shell.execute_reply.started":"2023-10-01T07:39:29.196381Z","shell.execute_reply":"2023-10-01T10:57:49.031065Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.11 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231001_074200-h800x6ur</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/deewhy/huggingface/runs/h800x6ur' target=\"_blank\">effortless-planet-38</a></strong> to <a href='https://wandb.ai/deewhy/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/deewhy/huggingface' target=\"_blank\">https://wandb.ai/deewhy/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/deewhy/huggingface/runs/h800x6ur' target=\"_blank\">https://wandb.ai/deewhy/huggingface/runs/h800x6ur</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='82500' max='82500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [82500/82500 3:15:14, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Name</th>\n      <th>Size</th>\n      <th>Index</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.313300</td>\n      <td>0.751000</td>\n      <td>0.824000</td>\n      <td>0.742795</td>\n      <td>intent_classification</td>\n      <td>5000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.313300</td>\n      <td>1.440783</td>\n      <td>0.763096</td>\n      <td>0.230205</td>\n      <td>slot_detection</td>\n      <td>2000</td>\n      <td>1</td>\n      <td>0.249222</td>\n      <td>0.213885</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.545500</td>\n      <td>0.835998</td>\n      <td>0.846200</td>\n      <td>0.785128</td>\n      <td>intent_classification</td>\n      <td>5000</td>\n      <td>0</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.545500</td>\n      <td>1.472930</td>\n      <td>0.768469</td>\n      <td>0.278186</td>\n      <td>slot_detection</td>\n      <td>2000</td>\n      <td>1</td>\n      <td>0.289383</td>\n      <td>0.267824</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.396400</td>\n      <td>0.938259</td>\n      <td>0.849200</td>\n      <td>0.798738</td>\n      <td>intent_classification</td>\n      <td>5000</td>\n      <td>0</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.396400</td>\n      <td>1.540279</td>\n      <td>0.766565</td>\n      <td>0.320360</td>\n      <td>slot_detection</td>\n      <td>2000</td>\n      <td>1</td>\n      <td>0.317669</td>\n      <td>0.323097</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.304000</td>\n      <td>1.052856</td>\n      <td>0.851400</td>\n      <td>0.800255</td>\n      <td>intent_classification</td>\n      <td>5000</td>\n      <td>0</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.304000</td>\n      <td>1.590327</td>\n      <td>0.767538</td>\n      <td>0.333730</td>\n      <td>slot_detection</td>\n      <td>2000</td>\n      <td>1</td>\n      <td>0.330540</td>\n      <td>0.336983</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.239100</td>\n      <td>1.105136</td>\n      <td>0.855800</td>\n      <td>0.808520</td>\n      <td>intent_classification</td>\n      <td>5000</td>\n      <td>0</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.239100</td>\n      <td>1.617182</td>\n      <td>0.766142</td>\n      <td>0.337002</td>\n      <td>slot_detection</td>\n      <td>2000</td>\n      <td>1</td>\n      <td>0.330846</td>\n      <td>0.343391</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.195500</td>\n      <td>1.117863</td>\n      <td>0.853200</td>\n      <td>0.807125</td>\n      <td>intent_classification</td>\n      <td>5000</td>\n      <td>0</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.195500</td>\n      <td>1.632844</td>\n      <td>0.766734</td>\n      <td>0.341534</td>\n      <td>slot_detection</td>\n      <td>2000</td>\n      <td>1</td>\n      <td>0.334873</td>\n      <td>0.348465</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.64k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fd4101201b94512a66c3ce5f456b748"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c683e233f6674b31b3368b579953d785"}},"metadata":{}},{"name":"stderr","text":"Trainer is attempting to log a value of \"intent_classification\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 33 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 36 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 19 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 72 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 27 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 80 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 13 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 66 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 38 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 91 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 47 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 100 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 23 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 76 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 39 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 92 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 52 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 29 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 82 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 21 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 20 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 73 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 49 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 42 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 95 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 44 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 15 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 55 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 53 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 17 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 70 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 14 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 56 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 59 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 34 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 45 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 98 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 24 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 89 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 86 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 32 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 77 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 26 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 37 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 90 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 87 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 41 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 94 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 12 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 97 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 35 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 63 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 102 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 65 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 48 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 68 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 50 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 43 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 96 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 105 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 58 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 40 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 93 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 28 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 67 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 46 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 99 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 18 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 71 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 61 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 54 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 60 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 25 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 106 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 81 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 74 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 79 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 85 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 16 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 69 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 103 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 11 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"slot_detection\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"intent_classification\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 20 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 38 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 52 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 13 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 47 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 100 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 21 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 44 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 19 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 72 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 36 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 89 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 56 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 45 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 98 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 28 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 49 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 23 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 76 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 53 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 66 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 14 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 29 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 12 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 33 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 86 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 106 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 60 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 91 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 39 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 92 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 27 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 65 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 73 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 82 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 40 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 93 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 102 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 50 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 17 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 70 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 48 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 18 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 26 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 59 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 58 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 15 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 97 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 34 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 80 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 37 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 68 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 105 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 24 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 87 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 61 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 81 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 43 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 96 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 90 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 32 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 55 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 85 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 71 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 41 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 63 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 77 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 35 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 67 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 79 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 74 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 25 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 94 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 42 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 95 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 103 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 54 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 16 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 69 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 11 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 46 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 99 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 84 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"slot_detection\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"intent_classification\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 38 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 29 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 82 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 47 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 100 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 14 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 34 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 13 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 49 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 53 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 15 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 20 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 50 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 52 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 18 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 71 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 19 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 24 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 68 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 77 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 43 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 96 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 36 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 27 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 80 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 12 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 66 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 72 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 39 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 92 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 44 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 67 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 97 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 91 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 23 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 76 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 40 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 93 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 73 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 45 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 41 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 94 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 35 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 48 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 56 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 61 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 98 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 89 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 87 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 59 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 60 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 26 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 65 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 17 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 70 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 25 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 21 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 74 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 33 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 32 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 28 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 42 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 95 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 86 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 105 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 106 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 37 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 102 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 85 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 11 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 79 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 46 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 99 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 16 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 69 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 81 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 58 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 63 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 90 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 55 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 103 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 54 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 84 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 104 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"slot_detection\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"intent_classification\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 19 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 72 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 36 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 13 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 66 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 29 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 47 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 100 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 38 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 26 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 15 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 56 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 49 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 82 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 12 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 65 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 39 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 41 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 94 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 14 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 67 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 45 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 98 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 91 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 52 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 37 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 90 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 68 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 59 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 20 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 35 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 24 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 77 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 60 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 89 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 53 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 106 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 34 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 44 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 11 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 102 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 27 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 80 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 40 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 93 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 21 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 55 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 42 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 87 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 18 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 33 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 86 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 28 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 73 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 92 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 81 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 43 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 96 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 17 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 70 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 23 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 58 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 25 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 79 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 48 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 76 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 32 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 50 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 71 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 97 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 16 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 69 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 95 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 74 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 61 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 46 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 99 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 63 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 105 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 85 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 54 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 103 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 84 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 110 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 101 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 104 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"slot_detection\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"intent_classification\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 38 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 52 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 15 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 68 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 56 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 45 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 36 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 13 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 66 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 14 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 33 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 86 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 19 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 47 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 100 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 29 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 43 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 72 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 91 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 39 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 92 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 23 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 76 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 53 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 59 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 49 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 44 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 40 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 93 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 34 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 18 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 71 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 60 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 20 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 73 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 89 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 41 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 94 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 87 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 21 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 97 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 35 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 28 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 42 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 102 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 12 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 65 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 96 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 27 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 58 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 26 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 24 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 77 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 80 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 82 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 32 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 61 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 17 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 70 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 37 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 90 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 95 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 98 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 79 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 106 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 67 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 63 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 55 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 25 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 48 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 50 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 74 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 81 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 54 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 103 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 85 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 46 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 99 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 105 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 11 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 16 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 69 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 101 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 84 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 75 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 78 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 110 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 104 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"slot_detection\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"intent_classification\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 13 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 6 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 34 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 87 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 27 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 38 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 80 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 7 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 66 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 36 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 89 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 18 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 71 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 29 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 45 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 19 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 52 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 49 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 47 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 3 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 56 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 32 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 21 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 74 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 59 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 14 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 44 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 72 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 43 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 96 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 100 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 91 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 15 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 5 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 58 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 39 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 92 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 20 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 53 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 102 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 12 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 65 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 60 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 26 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 33 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 106 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 82 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 23 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 68 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 50 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 2 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 41 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 94 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 86 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 67 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 54 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 73 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 42 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 24 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 10 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 28 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 35 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 9 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 55 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 77 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 98 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 46 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 99 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 11 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 25 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 37 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 90 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 76 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 63 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 97 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 48 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 17 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 70 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 8 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 61 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 40 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 85 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 93 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 95 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 103 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 81 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 79 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 16 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 69 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 105 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 84 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 78 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 101 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 110 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 75 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 104 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"slot_detection\" of type <class 'str'> for key \"eval/name\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nThere were missing keys in the checkpoint model loaded: ['Z', 'shared_encoder.embeddings.position_ids', 'shared_encoder.embeddings.word_embeddings.weight', 'shared_encoder.embeddings.LayerNorm.gates', 'shared_encoder.embeddings.LayerNorm.LN.weight', 'shared_encoder.embeddings.LayerNorm.LN.bias', 'shared_encoder.embeddings.LayerNorm.L1.weight', 'shared_encoder.embeddings.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.0.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.0.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.0.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.0.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.0.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.0.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.0.attention.output.dense.weight', 'shared_encoder.encoder.layer.0.attention.output.dense.bias', 'shared_encoder.encoder.layer.0.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.0.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.0.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.0.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.0.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.0.intermediate.dense.weight', 'shared_encoder.encoder.layer.0.intermediate.dense.bias', 'shared_encoder.encoder.layer.0.output.dense.weight', 'shared_encoder.encoder.layer.0.output.dense.bias', 'shared_encoder.encoder.layer.0.output.LayerNorm.gates', 'shared_encoder.encoder.layer.0.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.0.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.0.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.0.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.1.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.1.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.1.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.1.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.1.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.1.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.1.attention.output.dense.weight', 'shared_encoder.encoder.layer.1.attention.output.dense.bias', 'shared_encoder.encoder.layer.1.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.1.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.1.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.1.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.1.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.1.intermediate.dense.weight', 'shared_encoder.encoder.layer.1.intermediate.dense.bias', 'shared_encoder.encoder.layer.1.output.dense.weight', 'shared_encoder.encoder.layer.1.output.dense.bias', 'shared_encoder.encoder.layer.1.output.LayerNorm.gates', 'shared_encoder.encoder.layer.1.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.1.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.1.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.1.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.2.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.2.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.2.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.2.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.2.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.2.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.2.attention.output.dense.weight', 'shared_encoder.encoder.layer.2.attention.output.dense.bias', 'shared_encoder.encoder.layer.2.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.2.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.2.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.2.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.2.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.2.intermediate.dense.weight', 'shared_encoder.encoder.layer.2.intermediate.dense.bias', 'shared_encoder.encoder.layer.2.output.dense.weight', 'shared_encoder.encoder.layer.2.output.dense.bias', 'shared_encoder.encoder.layer.2.output.LayerNorm.gates', 'shared_encoder.encoder.layer.2.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.2.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.2.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.2.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.3.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.3.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.3.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.3.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.3.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.3.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.3.attention.output.dense.weight', 'shared_encoder.encoder.layer.3.attention.output.dense.bias', 'shared_encoder.encoder.layer.3.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.3.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.3.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.3.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.3.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.3.intermediate.dense.weight', 'shared_encoder.encoder.layer.3.intermediate.dense.bias', 'shared_encoder.encoder.layer.3.output.dense.weight', 'shared_encoder.encoder.layer.3.output.dense.bias', 'shared_encoder.encoder.layer.3.output.LayerNorm.gates', 'shared_encoder.encoder.layer.3.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.3.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.3.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.3.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.4.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.4.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.4.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.4.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.4.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.4.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.4.attention.output.dense.weight', 'shared_encoder.encoder.layer.4.attention.output.dense.bias', 'shared_encoder.encoder.layer.4.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.4.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.4.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.4.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.4.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.4.intermediate.dense.weight', 'shared_encoder.encoder.layer.4.intermediate.dense.bias', 'shared_encoder.encoder.layer.4.output.dense.weight', 'shared_encoder.encoder.layer.4.output.dense.bias', 'shared_encoder.encoder.layer.4.output.LayerNorm.gates', 'shared_encoder.encoder.layer.4.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.4.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.4.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.4.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.5.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.5.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.5.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.5.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.5.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.5.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.5.attention.output.dense.weight', 'shared_encoder.encoder.layer.5.attention.output.dense.bias', 'shared_encoder.encoder.layer.5.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.5.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.5.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.5.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.5.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.5.intermediate.dense.weight', 'shared_encoder.encoder.layer.5.intermediate.dense.bias', 'shared_encoder.encoder.layer.5.output.dense.weight', 'shared_encoder.encoder.layer.5.output.dense.bias', 'shared_encoder.encoder.layer.5.output.LayerNorm.gates', 'shared_encoder.encoder.layer.5.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.5.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.5.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.5.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.6.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.6.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.6.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.6.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.6.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.6.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.6.attention.output.dense.weight', 'shared_encoder.encoder.layer.6.attention.output.dense.bias', 'shared_encoder.encoder.layer.6.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.6.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.6.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.6.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.6.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.6.intermediate.dense.weight', 'shared_encoder.encoder.layer.6.intermediate.dense.bias', 'shared_encoder.encoder.layer.6.output.dense.weight', 'shared_encoder.encoder.layer.6.output.dense.bias', 'shared_encoder.encoder.layer.6.output.LayerNorm.gates', 'shared_encoder.encoder.layer.6.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.6.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.6.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.6.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.7.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.7.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.7.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.7.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.7.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.7.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.7.attention.output.dense.weight', 'shared_encoder.encoder.layer.7.attention.output.dense.bias', 'shared_encoder.encoder.layer.7.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.7.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.7.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.7.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.7.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.7.intermediate.dense.weight', 'shared_encoder.encoder.layer.7.intermediate.dense.bias', 'shared_encoder.encoder.layer.7.output.dense.weight', 'shared_encoder.encoder.layer.7.output.dense.bias', 'shared_encoder.encoder.layer.7.output.LayerNorm.gates', 'shared_encoder.encoder.layer.7.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.7.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.7.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.7.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.8.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.8.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.8.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.8.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.8.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.8.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.8.attention.output.dense.weight', 'shared_encoder.encoder.layer.8.attention.output.dense.bias', 'shared_encoder.encoder.layer.8.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.8.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.8.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.8.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.8.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.8.intermediate.dense.weight', 'shared_encoder.encoder.layer.8.intermediate.dense.bias', 'shared_encoder.encoder.layer.8.output.dense.weight', 'shared_encoder.encoder.layer.8.output.dense.bias', 'shared_encoder.encoder.layer.8.output.LayerNorm.gates', 'shared_encoder.encoder.layer.8.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.8.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.8.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.8.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.9.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.9.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.9.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.9.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.9.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.9.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.9.attention.output.dense.weight', 'shared_encoder.encoder.layer.9.attention.output.dense.bias', 'shared_encoder.encoder.layer.9.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.9.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.9.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.9.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.9.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.9.intermediate.dense.weight', 'shared_encoder.encoder.layer.9.intermediate.dense.bias', 'shared_encoder.encoder.layer.9.output.dense.weight', 'shared_encoder.encoder.layer.9.output.dense.bias', 'shared_encoder.encoder.layer.9.output.LayerNorm.gates', 'shared_encoder.encoder.layer.9.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.9.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.9.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.9.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.10.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.10.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.10.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.10.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.10.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.10.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.10.attention.output.dense.weight', 'shared_encoder.encoder.layer.10.attention.output.dense.bias', 'shared_encoder.encoder.layer.10.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.10.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.10.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.10.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.10.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.10.intermediate.dense.weight', 'shared_encoder.encoder.layer.10.intermediate.dense.bias', 'shared_encoder.encoder.layer.10.output.dense.weight', 'shared_encoder.encoder.layer.10.output.dense.bias', 'shared_encoder.encoder.layer.10.output.LayerNorm.gates', 'shared_encoder.encoder.layer.10.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.10.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.10.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.10.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.11.attention.self.query_proj.weight', 'shared_encoder.encoder.layer.11.attention.self.query_proj.bias', 'shared_encoder.encoder.layer.11.attention.self.key_proj.weight', 'shared_encoder.encoder.layer.11.attention.self.key_proj.bias', 'shared_encoder.encoder.layer.11.attention.self.value_proj.weight', 'shared_encoder.encoder.layer.11.attention.self.value_proj.bias', 'shared_encoder.encoder.layer.11.attention.output.dense.weight', 'shared_encoder.encoder.layer.11.attention.output.dense.bias', 'shared_encoder.encoder.layer.11.attention.output.LayerNorm.gates', 'shared_encoder.encoder.layer.11.attention.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.11.attention.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.11.attention.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.11.attention.output.LayerNorm.L1.bias', 'shared_encoder.encoder.layer.11.intermediate.dense.weight', 'shared_encoder.encoder.layer.11.intermediate.dense.bias', 'shared_encoder.encoder.layer.11.output.dense.weight', 'shared_encoder.encoder.layer.11.output.dense.bias', 'shared_encoder.encoder.layer.11.output.LayerNorm.gates', 'shared_encoder.encoder.layer.11.output.LayerNorm.LN.weight', 'shared_encoder.encoder.layer.11.output.LayerNorm.LN.bias', 'shared_encoder.encoder.layer.11.output.LayerNorm.L1.weight', 'shared_encoder.encoder.layer.11.output.LayerNorm.L1.bias', 'shared_encoder.encoder.rel_embeddings.weight', 'shared_encoder.encoder.LayerNorm.gates', 'shared_encoder.encoder.LayerNorm.LN.weight', 'shared_encoder.encoder.LayerNorm.LN.bias', 'shared_encoder.encoder.LayerNorm.L1.weight', 'shared_encoder.encoder.LayerNorm.L1.bias', 'shared_pooler.dense.weight', 'shared_pooler.dense.bias', 'task_models_list.0.deberta.embeddings.position_ids', 'task_models_list.0.deberta.embeddings.word_embeddings.weight', 'task_models_list.0.deberta.embeddings.LayerNorm.gates', 'task_models_list.0.deberta.embeddings.LayerNorm.LN.weight', 'task_models_list.0.deberta.embeddings.LayerNorm.LN.bias', 'task_models_list.0.deberta.embeddings.LayerNorm.L1.weight', 'task_models_list.0.deberta.embeddings.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.0.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.0.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.0.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.0.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.0.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.0.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.0.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.0.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.0.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.0.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.0.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.0.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.0.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.0.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.0.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.0.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.0.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.0.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.0.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.0.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.0.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.0.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.1.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.1.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.1.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.1.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.1.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.1.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.1.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.1.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.1.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.1.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.1.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.1.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.1.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.1.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.1.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.1.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.1.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.1.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.1.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.1.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.1.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.1.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.2.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.2.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.2.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.2.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.2.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.2.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.2.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.2.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.2.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.2.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.2.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.2.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.2.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.2.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.2.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.2.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.2.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.2.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.2.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.2.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.2.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.2.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.3.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.3.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.3.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.3.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.3.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.3.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.3.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.3.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.3.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.3.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.3.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.3.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.3.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.3.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.3.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.3.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.3.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.3.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.3.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.3.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.3.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.3.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.4.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.4.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.4.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.4.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.4.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.4.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.4.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.4.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.4.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.4.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.4.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.4.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.4.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.4.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.4.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.4.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.4.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.4.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.4.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.4.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.4.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.4.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.5.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.5.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.5.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.5.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.5.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.5.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.5.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.5.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.5.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.5.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.5.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.5.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.5.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.5.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.5.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.5.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.5.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.5.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.5.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.5.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.5.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.5.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.6.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.6.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.6.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.6.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.6.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.6.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.6.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.6.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.6.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.6.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.6.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.6.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.6.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.6.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.6.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.6.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.6.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.6.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.6.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.6.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.6.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.6.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.7.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.7.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.7.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.7.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.7.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.7.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.7.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.7.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.7.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.7.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.7.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.7.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.7.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.7.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.7.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.7.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.7.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.7.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.7.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.7.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.7.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.7.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.8.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.8.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.8.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.8.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.8.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.8.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.8.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.8.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.8.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.8.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.8.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.8.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.8.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.8.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.8.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.8.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.8.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.8.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.8.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.8.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.8.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.8.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.9.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.9.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.9.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.9.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.9.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.9.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.9.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.9.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.9.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.9.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.9.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.9.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.9.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.9.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.9.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.9.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.9.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.9.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.9.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.9.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.9.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.9.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.10.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.10.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.10.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.10.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.10.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.10.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.10.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.10.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.10.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.10.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.10.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.10.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.10.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.10.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.10.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.10.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.10.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.10.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.10.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.10.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.10.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.10.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.11.attention.self.query_proj.weight', 'task_models_list.0.deberta.encoder.layer.11.attention.self.query_proj.bias', 'task_models_list.0.deberta.encoder.layer.11.attention.self.key_proj.weight', 'task_models_list.0.deberta.encoder.layer.11.attention.self.key_proj.bias', 'task_models_list.0.deberta.encoder.layer.11.attention.self.value_proj.weight', 'task_models_list.0.deberta.encoder.layer.11.attention.self.value_proj.bias', 'task_models_list.0.deberta.encoder.layer.11.attention.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.11.attention.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.11.attention.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.11.attention.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.11.attention.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.11.attention.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.11.attention.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.layer.11.intermediate.dense.weight', 'task_models_list.0.deberta.encoder.layer.11.intermediate.dense.bias', 'task_models_list.0.deberta.encoder.layer.11.output.dense.weight', 'task_models_list.0.deberta.encoder.layer.11.output.dense.bias', 'task_models_list.0.deberta.encoder.layer.11.output.LayerNorm.gates', 'task_models_list.0.deberta.encoder.layer.11.output.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.layer.11.output.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.layer.11.output.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.layer.11.output.LayerNorm.L1.bias', 'task_models_list.0.deberta.encoder.rel_embeddings.weight', 'task_models_list.0.deberta.encoder.LayerNorm.gates', 'task_models_list.0.deberta.encoder.LayerNorm.LN.weight', 'task_models_list.0.deberta.encoder.LayerNorm.LN.bias', 'task_models_list.0.deberta.encoder.LayerNorm.L1.weight', 'task_models_list.0.deberta.encoder.LayerNorm.L1.bias', 'task_models_list.0.pooler.dense.weight', 'task_models_list.0.pooler.dense.bias', 'task_models_list.0.classifier.weight', 'task_models_list.0.classifier.bias', 'task_models_list.1.deberta.embeddings.position_ids', 'task_models_list.1.deberta.embeddings.word_embeddings.0.weight', 'task_models_list.1.deberta.embeddings.LayerNorm.gates', 'task_models_list.1.deberta.embeddings.LayerNorm.LN.weight', 'task_models_list.1.deberta.embeddings.LayerNorm.LN.bias', 'task_models_list.1.deberta.embeddings.LayerNorm.L1.weight', 'task_models_list.1.deberta.embeddings.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.0.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.0.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.0.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.0.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.0.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.0.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.0.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.0.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.0.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.0.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.0.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.0.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.0.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.0.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.0.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.0.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.0.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.0.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.0.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.0.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.0.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.0.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.1.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.1.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.1.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.1.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.1.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.1.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.1.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.1.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.1.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.1.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.1.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.1.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.1.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.1.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.1.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.1.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.1.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.1.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.1.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.1.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.1.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.1.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.2.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.2.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.2.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.2.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.2.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.2.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.2.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.2.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.2.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.2.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.2.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.2.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.2.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.2.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.2.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.2.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.2.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.2.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.2.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.2.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.2.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.2.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.3.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.3.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.3.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.3.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.3.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.3.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.3.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.3.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.3.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.3.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.3.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.3.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.3.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.3.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.3.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.3.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.3.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.3.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.3.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.3.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.3.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.3.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.4.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.4.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.4.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.4.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.4.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.4.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.4.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.4.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.4.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.4.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.4.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.4.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.4.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.4.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.4.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.4.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.4.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.4.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.4.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.4.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.4.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.4.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.5.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.5.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.5.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.5.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.5.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.5.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.5.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.5.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.5.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.5.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.5.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.5.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.5.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.5.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.5.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.5.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.5.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.5.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.5.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.5.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.5.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.5.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.6.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.6.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.6.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.6.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.6.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.6.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.6.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.6.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.6.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.6.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.6.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.6.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.6.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.6.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.6.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.6.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.6.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.6.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.6.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.6.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.6.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.6.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.7.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.7.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.7.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.7.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.7.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.7.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.7.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.7.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.7.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.7.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.7.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.7.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.7.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.7.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.7.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.7.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.7.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.7.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.7.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.7.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.7.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.7.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.8.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.8.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.8.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.8.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.8.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.8.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.8.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.8.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.8.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.8.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.8.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.8.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.8.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.8.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.8.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.8.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.8.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.8.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.8.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.8.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.8.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.8.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.9.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.9.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.9.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.9.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.9.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.9.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.9.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.9.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.9.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.9.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.9.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.9.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.9.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.9.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.9.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.9.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.9.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.9.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.9.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.9.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.9.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.9.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.10.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.10.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.10.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.10.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.10.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.10.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.10.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.10.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.10.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.10.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.10.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.10.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.10.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.10.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.10.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.10.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.10.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.10.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.10.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.10.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.10.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.10.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.11.attention.self.query_proj.weight', 'task_models_list.1.deberta.encoder.layer.11.attention.self.query_proj.bias', 'task_models_list.1.deberta.encoder.layer.11.attention.self.key_proj.weight', 'task_models_list.1.deberta.encoder.layer.11.attention.self.key_proj.bias', 'task_models_list.1.deberta.encoder.layer.11.attention.self.value_proj.weight', 'task_models_list.1.deberta.encoder.layer.11.attention.self.value_proj.bias', 'task_models_list.1.deberta.encoder.layer.11.attention.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.11.attention.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.11.attention.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.11.attention.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.11.attention.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.11.attention.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.11.attention.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.layer.11.intermediate.dense.weight', 'task_models_list.1.deberta.encoder.layer.11.intermediate.dense.bias', 'task_models_list.1.deberta.encoder.layer.11.output.dense.weight', 'task_models_list.1.deberta.encoder.layer.11.output.dense.bias', 'task_models_list.1.deberta.encoder.layer.11.output.LayerNorm.gates', 'task_models_list.1.deberta.encoder.layer.11.output.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.layer.11.output.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.layer.11.output.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.layer.11.output.LayerNorm.L1.bias', 'task_models_list.1.deberta.encoder.rel_embeddings.weight', 'task_models_list.1.deberta.encoder.LayerNorm.gates', 'task_models_list.1.deberta.encoder.LayerNorm.LN.weight', 'task_models_list.1.deberta.encoder.LayerNorm.LN.bias', 'task_models_list.1.deberta.encoder.LayerNorm.L1.weight', 'task_models_list.1.deberta.encoder.LayerNorm.L1.bias', 'task_models_list.1.classifier.weight', 'task_models_list.1.classifier.bias', 'task_models_list.1.auto.embeddings.position_ids', 'task_models_list.1.auto.embeddings.word_embeddings.0.weight', 'task_models_list.1.auto.embeddings.LayerNorm.gates', 'task_models_list.1.auto.embeddings.LayerNorm.LN.weight', 'task_models_list.1.auto.embeddings.LayerNorm.LN.bias', 'task_models_list.1.auto.embeddings.LayerNorm.L1.weight', 'task_models_list.1.auto.embeddings.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.0.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.0.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.0.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.0.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.0.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.0.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.0.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.0.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.0.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.0.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.0.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.0.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.0.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.0.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.0.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.0.output.dense.weight', 'task_models_list.1.auto.encoder.layer.0.output.dense.bias', 'task_models_list.1.auto.encoder.layer.0.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.0.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.0.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.0.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.0.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.1.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.1.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.1.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.1.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.1.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.1.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.1.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.1.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.1.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.1.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.1.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.1.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.1.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.1.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.1.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.1.output.dense.weight', 'task_models_list.1.auto.encoder.layer.1.output.dense.bias', 'task_models_list.1.auto.encoder.layer.1.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.1.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.1.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.1.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.1.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.2.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.2.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.2.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.2.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.2.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.2.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.2.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.2.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.2.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.2.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.2.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.2.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.2.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.2.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.2.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.2.output.dense.weight', 'task_models_list.1.auto.encoder.layer.2.output.dense.bias', 'task_models_list.1.auto.encoder.layer.2.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.2.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.2.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.2.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.2.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.3.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.3.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.3.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.3.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.3.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.3.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.3.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.3.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.3.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.3.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.3.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.3.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.3.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.3.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.3.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.3.output.dense.weight', 'task_models_list.1.auto.encoder.layer.3.output.dense.bias', 'task_models_list.1.auto.encoder.layer.3.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.3.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.3.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.3.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.3.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.4.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.4.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.4.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.4.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.4.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.4.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.4.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.4.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.4.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.4.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.4.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.4.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.4.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.4.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.4.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.4.output.dense.weight', 'task_models_list.1.auto.encoder.layer.4.output.dense.bias', 'task_models_list.1.auto.encoder.layer.4.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.4.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.4.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.4.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.4.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.5.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.5.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.5.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.5.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.5.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.5.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.5.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.5.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.5.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.5.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.5.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.5.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.5.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.5.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.5.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.5.output.dense.weight', 'task_models_list.1.auto.encoder.layer.5.output.dense.bias', 'task_models_list.1.auto.encoder.layer.5.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.5.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.5.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.5.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.5.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.6.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.6.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.6.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.6.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.6.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.6.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.6.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.6.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.6.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.6.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.6.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.6.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.6.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.6.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.6.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.6.output.dense.weight', 'task_models_list.1.auto.encoder.layer.6.output.dense.bias', 'task_models_list.1.auto.encoder.layer.6.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.6.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.6.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.6.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.6.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.7.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.7.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.7.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.7.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.7.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.7.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.7.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.7.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.7.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.7.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.7.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.7.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.7.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.7.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.7.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.7.output.dense.weight', 'task_models_list.1.auto.encoder.layer.7.output.dense.bias', 'task_models_list.1.auto.encoder.layer.7.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.7.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.7.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.7.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.7.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.8.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.8.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.8.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.8.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.8.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.8.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.8.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.8.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.8.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.8.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.8.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.8.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.8.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.8.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.8.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.8.output.dense.weight', 'task_models_list.1.auto.encoder.layer.8.output.dense.bias', 'task_models_list.1.auto.encoder.layer.8.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.8.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.8.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.8.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.8.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.9.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.9.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.9.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.9.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.9.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.9.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.9.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.9.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.9.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.9.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.9.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.9.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.9.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.9.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.9.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.9.output.dense.weight', 'task_models_list.1.auto.encoder.layer.9.output.dense.bias', 'task_models_list.1.auto.encoder.layer.9.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.9.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.9.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.9.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.9.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.10.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.10.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.10.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.10.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.10.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.10.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.10.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.10.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.10.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.10.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.10.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.10.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.10.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.10.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.10.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.10.output.dense.weight', 'task_models_list.1.auto.encoder.layer.10.output.dense.bias', 'task_models_list.1.auto.encoder.layer.10.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.10.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.10.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.10.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.10.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.11.attention.self.query_proj.weight', 'task_models_list.1.auto.encoder.layer.11.attention.self.query_proj.bias', 'task_models_list.1.auto.encoder.layer.11.attention.self.key_proj.weight', 'task_models_list.1.auto.encoder.layer.11.attention.self.key_proj.bias', 'task_models_list.1.auto.encoder.layer.11.attention.self.value_proj.weight', 'task_models_list.1.auto.encoder.layer.11.attention.self.value_proj.bias', 'task_models_list.1.auto.encoder.layer.11.attention.output.dense.weight', 'task_models_list.1.auto.encoder.layer.11.attention.output.dense.bias', 'task_models_list.1.auto.encoder.layer.11.attention.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.11.attention.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.11.attention.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.11.attention.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.11.attention.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.layer.11.intermediate.dense.weight', 'task_models_list.1.auto.encoder.layer.11.intermediate.dense.bias', 'task_models_list.1.auto.encoder.layer.11.output.dense.weight', 'task_models_list.1.auto.encoder.layer.11.output.dense.bias', 'task_models_list.1.auto.encoder.layer.11.output.LayerNorm.gates', 'task_models_list.1.auto.encoder.layer.11.output.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.layer.11.output.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.layer.11.output.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.layer.11.output.LayerNorm.L1.bias', 'task_models_list.1.auto.encoder.rel_embeddings.weight', 'task_models_list.1.auto.encoder.LayerNorm.gates', 'task_models_list.1.auto.encoder.LayerNorm.LN.weight', 'task_models_list.1.auto.encoder.LayerNorm.LN.bias', 'task_models_list.1.auto.encoder.LayerNorm.L1.weight', 'task_models_list.1.auto.encoder.LayerNorm.L1.bias'].\nThere were unexpected keys in the checkpoint model loaded: ['deberta.embeddings.position_ids', 'deberta.embeddings.word_embeddings.weight', 'deberta.embeddings.LayerNorm.gates', 'deberta.embeddings.LayerNorm.LN.weight', 'deberta.embeddings.LayerNorm.LN.bias', 'deberta.embeddings.LayerNorm.L1.weight', 'deberta.embeddings.LayerNorm.L1.bias', 'deberta.encoder.layer.0.attention.self.query_proj.weight', 'deberta.encoder.layer.0.attention.self.query_proj.bias', 'deberta.encoder.layer.0.attention.self.key_proj.weight', 'deberta.encoder.layer.0.attention.self.key_proj.bias', 'deberta.encoder.layer.0.attention.self.value_proj.weight', 'deberta.encoder.layer.0.attention.self.value_proj.bias', 'deberta.encoder.layer.0.attention.output.dense.weight', 'deberta.encoder.layer.0.attention.output.dense.bias', 'deberta.encoder.layer.0.attention.output.LayerNorm.gates', 'deberta.encoder.layer.0.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.0.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.0.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.0.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.0.intermediate.dense.weight', 'deberta.encoder.layer.0.intermediate.dense.bias', 'deberta.encoder.layer.0.output.dense.weight', 'deberta.encoder.layer.0.output.dense.bias', 'deberta.encoder.layer.0.output.LayerNorm.gates', 'deberta.encoder.layer.0.output.LayerNorm.LN.weight', 'deberta.encoder.layer.0.output.LayerNorm.LN.bias', 'deberta.encoder.layer.0.output.LayerNorm.L1.weight', 'deberta.encoder.layer.0.output.LayerNorm.L1.bias', 'deberta.encoder.layer.1.attention.self.query_proj.weight', 'deberta.encoder.layer.1.attention.self.query_proj.bias', 'deberta.encoder.layer.1.attention.self.key_proj.weight', 'deberta.encoder.layer.1.attention.self.key_proj.bias', 'deberta.encoder.layer.1.attention.self.value_proj.weight', 'deberta.encoder.layer.1.attention.self.value_proj.bias', 'deberta.encoder.layer.1.attention.output.dense.weight', 'deberta.encoder.layer.1.attention.output.dense.bias', 'deberta.encoder.layer.1.attention.output.LayerNorm.gates', 'deberta.encoder.layer.1.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.1.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.1.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.1.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.1.intermediate.dense.weight', 'deberta.encoder.layer.1.intermediate.dense.bias', 'deberta.encoder.layer.1.output.dense.weight', 'deberta.encoder.layer.1.output.dense.bias', 'deberta.encoder.layer.1.output.LayerNorm.gates', 'deberta.encoder.layer.1.output.LayerNorm.LN.weight', 'deberta.encoder.layer.1.output.LayerNorm.LN.bias', 'deberta.encoder.layer.1.output.LayerNorm.L1.weight', 'deberta.encoder.layer.1.output.LayerNorm.L1.bias', 'deberta.encoder.layer.2.attention.self.query_proj.weight', 'deberta.encoder.layer.2.attention.self.query_proj.bias', 'deberta.encoder.layer.2.attention.self.key_proj.weight', 'deberta.encoder.layer.2.attention.self.key_proj.bias', 'deberta.encoder.layer.2.attention.self.value_proj.weight', 'deberta.encoder.layer.2.attention.self.value_proj.bias', 'deberta.encoder.layer.2.attention.output.dense.weight', 'deberta.encoder.layer.2.attention.output.dense.bias', 'deberta.encoder.layer.2.attention.output.LayerNorm.gates', 'deberta.encoder.layer.2.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.2.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.2.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.2.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.2.intermediate.dense.weight', 'deberta.encoder.layer.2.intermediate.dense.bias', 'deberta.encoder.layer.2.output.dense.weight', 'deberta.encoder.layer.2.output.dense.bias', 'deberta.encoder.layer.2.output.LayerNorm.gates', 'deberta.encoder.layer.2.output.LayerNorm.LN.weight', 'deberta.encoder.layer.2.output.LayerNorm.LN.bias', 'deberta.encoder.layer.2.output.LayerNorm.L1.weight', 'deberta.encoder.layer.2.output.LayerNorm.L1.bias', 'deberta.encoder.layer.3.attention.self.query_proj.weight', 'deberta.encoder.layer.3.attention.self.query_proj.bias', 'deberta.encoder.layer.3.attention.self.key_proj.weight', 'deberta.encoder.layer.3.attention.self.key_proj.bias', 'deberta.encoder.layer.3.attention.self.value_proj.weight', 'deberta.encoder.layer.3.attention.self.value_proj.bias', 'deberta.encoder.layer.3.attention.output.dense.weight', 'deberta.encoder.layer.3.attention.output.dense.bias', 'deberta.encoder.layer.3.attention.output.LayerNorm.gates', 'deberta.encoder.layer.3.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.3.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.3.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.3.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.3.intermediate.dense.weight', 'deberta.encoder.layer.3.intermediate.dense.bias', 'deberta.encoder.layer.3.output.dense.weight', 'deberta.encoder.layer.3.output.dense.bias', 'deberta.encoder.layer.3.output.LayerNorm.gates', 'deberta.encoder.layer.3.output.LayerNorm.LN.weight', 'deberta.encoder.layer.3.output.LayerNorm.LN.bias', 'deberta.encoder.layer.3.output.LayerNorm.L1.weight', 'deberta.encoder.layer.3.output.LayerNorm.L1.bias', 'deberta.encoder.layer.4.attention.self.query_proj.weight', 'deberta.encoder.layer.4.attention.self.query_proj.bias', 'deberta.encoder.layer.4.attention.self.key_proj.weight', 'deberta.encoder.layer.4.attention.self.key_proj.bias', 'deberta.encoder.layer.4.attention.self.value_proj.weight', 'deberta.encoder.layer.4.attention.self.value_proj.bias', 'deberta.encoder.layer.4.attention.output.dense.weight', 'deberta.encoder.layer.4.attention.output.dense.bias', 'deberta.encoder.layer.4.attention.output.LayerNorm.gates', 'deberta.encoder.layer.4.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.4.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.4.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.4.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.4.intermediate.dense.weight', 'deberta.encoder.layer.4.intermediate.dense.bias', 'deberta.encoder.layer.4.output.dense.weight', 'deberta.encoder.layer.4.output.dense.bias', 'deberta.encoder.layer.4.output.LayerNorm.gates', 'deberta.encoder.layer.4.output.LayerNorm.LN.weight', 'deberta.encoder.layer.4.output.LayerNorm.LN.bias', 'deberta.encoder.layer.4.output.LayerNorm.L1.weight', 'deberta.encoder.layer.4.output.LayerNorm.L1.bias', 'deberta.encoder.layer.5.attention.self.query_proj.weight', 'deberta.encoder.layer.5.attention.self.query_proj.bias', 'deberta.encoder.layer.5.attention.self.key_proj.weight', 'deberta.encoder.layer.5.attention.self.key_proj.bias', 'deberta.encoder.layer.5.attention.self.value_proj.weight', 'deberta.encoder.layer.5.attention.self.value_proj.bias', 'deberta.encoder.layer.5.attention.output.dense.weight', 'deberta.encoder.layer.5.attention.output.dense.bias', 'deberta.encoder.layer.5.attention.output.LayerNorm.gates', 'deberta.encoder.layer.5.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.5.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.5.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.5.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.5.intermediate.dense.weight', 'deberta.encoder.layer.5.intermediate.dense.bias', 'deberta.encoder.layer.5.output.dense.weight', 'deberta.encoder.layer.5.output.dense.bias', 'deberta.encoder.layer.5.output.LayerNorm.gates', 'deberta.encoder.layer.5.output.LayerNorm.LN.weight', 'deberta.encoder.layer.5.output.LayerNorm.LN.bias', 'deberta.encoder.layer.5.output.LayerNorm.L1.weight', 'deberta.encoder.layer.5.output.LayerNorm.L1.bias', 'deberta.encoder.layer.6.attention.self.query_proj.weight', 'deberta.encoder.layer.6.attention.self.query_proj.bias', 'deberta.encoder.layer.6.attention.self.key_proj.weight', 'deberta.encoder.layer.6.attention.self.key_proj.bias', 'deberta.encoder.layer.6.attention.self.value_proj.weight', 'deberta.encoder.layer.6.attention.self.value_proj.bias', 'deberta.encoder.layer.6.attention.output.dense.weight', 'deberta.encoder.layer.6.attention.output.dense.bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.gates', 'deberta.encoder.layer.6.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.6.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.6.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.6.intermediate.dense.weight', 'deberta.encoder.layer.6.intermediate.dense.bias', 'deberta.encoder.layer.6.output.dense.weight', 'deberta.encoder.layer.6.output.dense.bias', 'deberta.encoder.layer.6.output.LayerNorm.gates', 'deberta.encoder.layer.6.output.LayerNorm.LN.weight', 'deberta.encoder.layer.6.output.LayerNorm.LN.bias', 'deberta.encoder.layer.6.output.LayerNorm.L1.weight', 'deberta.encoder.layer.6.output.LayerNorm.L1.bias', 'deberta.encoder.layer.7.attention.self.query_proj.weight', 'deberta.encoder.layer.7.attention.self.query_proj.bias', 'deberta.encoder.layer.7.attention.self.key_proj.weight', 'deberta.encoder.layer.7.attention.self.key_proj.bias', 'deberta.encoder.layer.7.attention.self.value_proj.weight', 'deberta.encoder.layer.7.attention.self.value_proj.bias', 'deberta.encoder.layer.7.attention.output.dense.weight', 'deberta.encoder.layer.7.attention.output.dense.bias', 'deberta.encoder.layer.7.attention.output.LayerNorm.gates', 'deberta.encoder.layer.7.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.7.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.7.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.7.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.7.intermediate.dense.weight', 'deberta.encoder.layer.7.intermediate.dense.bias', 'deberta.encoder.layer.7.output.dense.weight', 'deberta.encoder.layer.7.output.dense.bias', 'deberta.encoder.layer.7.output.LayerNorm.gates', 'deberta.encoder.layer.7.output.LayerNorm.LN.weight', 'deberta.encoder.layer.7.output.LayerNorm.LN.bias', 'deberta.encoder.layer.7.output.LayerNorm.L1.weight', 'deberta.encoder.layer.7.output.LayerNorm.L1.bias', 'deberta.encoder.layer.8.attention.self.query_proj.weight', 'deberta.encoder.layer.8.attention.self.query_proj.bias', 'deberta.encoder.layer.8.attention.self.key_proj.weight', 'deberta.encoder.layer.8.attention.self.key_proj.bias', 'deberta.encoder.layer.8.attention.self.value_proj.weight', 'deberta.encoder.layer.8.attention.self.value_proj.bias', 'deberta.encoder.layer.8.attention.output.dense.weight', 'deberta.encoder.layer.8.attention.output.dense.bias', 'deberta.encoder.layer.8.attention.output.LayerNorm.gates', 'deberta.encoder.layer.8.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.8.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.8.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.8.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.8.intermediate.dense.weight', 'deberta.encoder.layer.8.intermediate.dense.bias', 'deberta.encoder.layer.8.output.dense.weight', 'deberta.encoder.layer.8.output.dense.bias', 'deberta.encoder.layer.8.output.LayerNorm.gates', 'deberta.encoder.layer.8.output.LayerNorm.LN.weight', 'deberta.encoder.layer.8.output.LayerNorm.LN.bias', 'deberta.encoder.layer.8.output.LayerNorm.L1.weight', 'deberta.encoder.layer.8.output.LayerNorm.L1.bias', 'deberta.encoder.layer.9.attention.self.query_proj.weight', 'deberta.encoder.layer.9.attention.self.query_proj.bias', 'deberta.encoder.layer.9.attention.self.key_proj.weight', 'deberta.encoder.layer.9.attention.self.key_proj.bias', 'deberta.encoder.layer.9.attention.self.value_proj.weight', 'deberta.encoder.layer.9.attention.self.value_proj.bias', 'deberta.encoder.layer.9.attention.output.dense.weight', 'deberta.encoder.layer.9.attention.output.dense.bias', 'deberta.encoder.layer.9.attention.output.LayerNorm.gates', 'deberta.encoder.layer.9.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.9.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.9.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.9.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.9.intermediate.dense.weight', 'deberta.encoder.layer.9.intermediate.dense.bias', 'deberta.encoder.layer.9.output.dense.weight', 'deberta.encoder.layer.9.output.dense.bias', 'deberta.encoder.layer.9.output.LayerNorm.gates', 'deberta.encoder.layer.9.output.LayerNorm.LN.weight', 'deberta.encoder.layer.9.output.LayerNorm.LN.bias', 'deberta.encoder.layer.9.output.LayerNorm.L1.weight', 'deberta.encoder.layer.9.output.LayerNorm.L1.bias', 'deberta.encoder.layer.10.attention.self.query_proj.weight', 'deberta.encoder.layer.10.attention.self.query_proj.bias', 'deberta.encoder.layer.10.attention.self.key_proj.weight', 'deberta.encoder.layer.10.attention.self.key_proj.bias', 'deberta.encoder.layer.10.attention.self.value_proj.weight', 'deberta.encoder.layer.10.attention.self.value_proj.bias', 'deberta.encoder.layer.10.attention.output.dense.weight', 'deberta.encoder.layer.10.attention.output.dense.bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.gates', 'deberta.encoder.layer.10.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.10.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.10.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.10.intermediate.dense.weight', 'deberta.encoder.layer.10.intermediate.dense.bias', 'deberta.encoder.layer.10.output.dense.weight', 'deberta.encoder.layer.10.output.dense.bias', 'deberta.encoder.layer.10.output.LayerNorm.gates', 'deberta.encoder.layer.10.output.LayerNorm.LN.weight', 'deberta.encoder.layer.10.output.LayerNorm.LN.bias', 'deberta.encoder.layer.10.output.LayerNorm.L1.weight', 'deberta.encoder.layer.10.output.LayerNorm.L1.bias', 'deberta.encoder.layer.11.attention.self.query_proj.weight', 'deberta.encoder.layer.11.attention.self.query_proj.bias', 'deberta.encoder.layer.11.attention.self.key_proj.weight', 'deberta.encoder.layer.11.attention.self.key_proj.bias', 'deberta.encoder.layer.11.attention.self.value_proj.weight', 'deberta.encoder.layer.11.attention.self.value_proj.bias', 'deberta.encoder.layer.11.attention.output.dense.weight', 'deberta.encoder.layer.11.attention.output.dense.bias', 'deberta.encoder.layer.11.attention.output.LayerNorm.gates', 'deberta.encoder.layer.11.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.11.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.11.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.11.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.11.intermediate.dense.weight', 'deberta.encoder.layer.11.intermediate.dense.bias', 'deberta.encoder.layer.11.output.dense.weight', 'deberta.encoder.layer.11.output.dense.bias', 'deberta.encoder.layer.11.output.LayerNorm.gates', 'deberta.encoder.layer.11.output.LayerNorm.LN.weight', 'deberta.encoder.layer.11.output.LayerNorm.LN.bias', 'deberta.encoder.layer.11.output.LayerNorm.L1.weight', 'deberta.encoder.layer.11.output.LayerNorm.L1.bias', 'deberta.encoder.rel_embeddings.weight', 'deberta.encoder.LayerNorm.gates', 'deberta.encoder.LayerNorm.LN.weight', 'deberta.encoder.LayerNorm.LN.bias', 'deberta.encoder.LayerNorm.L1.weight', 'deberta.encoder.LayerNorm.L1.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias'].\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=82500, training_loss=0.49897312677556815, metrics={'train_runtime': 11770.7301, 'train_samples_per_second': 56.071, 'train_steps_per_second': 7.009, 'total_flos': 9.481580798976e+16, 'train_loss': 0.49897312677556815, 'epoch': 6.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_state()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:02:35.411762Z","iopub.execute_input":"2023-10-01T11:02:35.412103Z","iopub.status.idle":"2023-10-01T11:02:35.420139Z","shell.execute_reply.started":"2023-10-01T11:02:35.412077Z","shell.execute_reply":"2023-10-01T11:02:35.419207Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"models.save_pretrained(\"/kaggle/working/model_save_pretrained\")\ntz.save_pretrained(\"/kaggle/working/tokenizer_save_pretrained\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:05:48.433452Z","iopub.execute_input":"2023-10-01T11:05:48.433809Z","iopub.status.idle":"2023-10-01T11:05:52.877802Z","shell.execute_reply.started":"2023-10-01T11:05:48.433782Z","shell.execute_reply":"2023-10-01T11:05:52.876850Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/tokenizer_save_pretrained/tokenizer_config.json',\n '/kaggle/working/tokenizer_save_pretrained/special_tokens_map.json',\n '/kaggle/working/tokenizer_save_pretrained/spm.model',\n '/kaggle/working/tokenizer_save_pretrained/added_tokens.json',\n '/kaggle/working/tokenizer_save_pretrained/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"models.save_pretrained(\"models_6epochs\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T20:10:30.352561Z","iopub.execute_input":"2023-09-25T20:10:30.353210Z","iopub.status.idle":"2023-09-25T20:10:34.045976Z","shell.execute_reply.started":"2023-09-25T20:10:30.353164Z","shell.execute_reply":"2023-09-25T20:10:34.044675Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T20:11:32.977173Z","iopub.execute_input":"2023-09-25T20:11:32.977556Z","iopub.status.idle":"2023-09-25T20:11:33.065940Z","shell.execute_reply.started":"2023-09-25T20:11:32.977524Z","shell.execute_reply":"2023-09-25T20:11:33.060993Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/vocab.txt',\n 'tokenizer/added_tokens.json',\n 'tokenizer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/working/latest_save_model\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:06:30.619843Z","iopub.execute_input":"2023-10-01T11:06:30.620181Z","iopub.status.idle":"2023-10-01T11:06:36.676976Z","shell.execute_reply.started":"2023-10-01T11:06:30.620153Z","shell.execute_reply":"2023-10-01T11:06:36.675932Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token 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","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:16:40.411629Z","iopub.execute_input":"2023-10-01T11:16:40.412876Z","iopub.status.idle":"2023-10-01T11:16:42.068216Z","shell.execute_reply.started":"2023-10-01T11:16:40.412839Z","shell.execute_reply":"2023-10-01T11:16:42.066734Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"models.push_to_hub(\"deewhy26/dberta-v3-finetuned-mt\", push_adapter=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:17:45.484997Z","iopub.execute_input":"2023-10-01T11:17:45.485340Z","iopub.status.idle":"2023-10-01T11:17:52.870536Z","shell.execute_reply.started":"2023-10-01T11:17:45.485312Z","shell.execute_reply":"2023-10-01T11:17:52.869500Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/deewhy26/dberta-v3-finetuned-mt/commit/ae92dcd20a824320440524e138752ea1571826a8', commit_message='Upload model', commit_description='', oid='ae92dcd20a824320440524e138752ea1571826a8', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"!zip -r latest_run.zip /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:19:04.253740Z","iopub.execute_input":"2023-10-01T11:19:04.254122Z","iopub.status.idle":"2023-10-01T11:26:48.477714Z","shell.execute_reply.started":"2023-10-01T11:19:04.254098Z","shell.execute_reply":"2023-10-01T11:26:48.476221Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/models/ (stored 0%)\n  adding: kaggle/working/models/multitask_model/ (stored 0%)\n  adding: kaggle/working/models/multitask_model/trainer_state.json (deflated 79%)\n  adding: kaggle/working/models/multitask_model/runs/ (stored 0%)\n  adding: kaggle/working/models/multitask_model/runs/Sep26_12-59-42_f6b2fa15f51e/ (stored 0%)\n  adding: kaggle/working/models/multitask_model/runs/Sep26_12-59-42_f6b2fa15f51e/events.out.tfevents.1695733247.f6b2fa15f51e.28.0 (deflated 64%)\n  adding: kaggle/working/models/multitask_model/runs/Oct01_07-40-47_47601b89e0b8/ (stored 0%)\n  adding: kaggle/working/models/multitask_model/runs/Oct01_07-40-47_47601b89e0b8/events.out.tfevents.1696146098.47601b89e0b8.27.0 (deflated 64%)\n  adding: kaggle/working/model_tasknet_6epoch.zip (stored 0%)\n  adding: kaggle/working/model_save_pretrained/ (stored 0%)\n  adding: kaggle/working/model_save_pretrained/pytorch_model.bin (deflated 21%)\n  adding: kaggle/working/model_save_pretrained/config.json (deflated 12%)\n  adding: kaggle/working/tasknet_6epochs-adapter/ (stored 0%)\n  adding: kaggle/working/tasknet_6epochs-adapter/pytorch_model.bin (deflated 7%)\n  adding: kaggle/working/tasknet_6epochs-adapter/config.json (deflated 74%)\n  adding: kaggle/working/tasknet_6epochs/ (stored 0%)\n  adding: kaggle/working/tasknet_6epochs/pytorch_model.bin (deflated 22%)\n  adding: kaggle/working/tasknet_6epochs/config.json (deflated 69%)\n  adding: kaggle/working/tokenizer_save_pretrained/ (stored 0%)\n  adding: kaggle/working/tokenizer_save_pretrained/tokenizer_config.json (deflated 45%)\n  adding: kaggle/working/tokenizer_save_pretrained/special_tokens_map.json (deflated 54%)\n  adding: kaggle/working/tokenizer_save_pretrained/added_tokens.json (stored 0%)\n  adding: kaggle/working/tokenizer_save_pretrained/spm.model (deflated 46%)\n  adding: kaggle/working/tokenizer_save_pretrained/tokenizer.json (deflated 76%)\n  adding: kaggle/working/latest_save_model-adapter/ (stored 0%)\n  adding: kaggle/working/latest_save_model-adapter/pytorch_model.bin (deflated 7%)\n  adding: kaggle/working/latest_save_model-adapter/config.json (deflated 74%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n  adding: kaggle/working/latest_save_model/ (stored 0%)\n  adding: kaggle/working/latest_save_model/pytorch_model.bin (deflated 21%)\n  adding: kaggle/working/latest_save_model/config.json (deflated 69%)\n  adding: kaggle/working/model_tasknet_adapter_6epoch.zip (stored 0%)\n  adding: kaggle/working/output.jsonl (deflated 92%)\n  adding: kaggle/working/wandb/ (stored 0%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/ (stored 0%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/files/ (stored 0%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/files/config.yaml (deflated 78%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/files/wandb-summary.json (deflated 66%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/files/output.log (deflated 96%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/files/wandb-metadata.json (deflated 60%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/files/requirements.txt (deflated 58%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/files/conda-environment.yaml (deflated 66%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/run-h800x6ur.wandb (deflated 83%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/logs/ (stored 0%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/logs/debug-internal.log (deflated 95%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/logs/debug.log (deflated 76%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/tmp/ (stored 0%)\n  adding: kaggle/working/wandb/run-20231001_074200-h800x6ur/tmp/code/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/files/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/files/config.yaml (deflated 78%)\n  adding: kaggle/working/wandb/latest-run/files/wandb-summary.json (deflated 66%)\n  adding: kaggle/working/wandb/latest-run/files/output.log (deflated 96%)\n  adding: kaggle/working/wandb/latest-run/files/wandb-metadata.json (deflated 60%)\n  adding: kaggle/working/wandb/latest-run/files/requirements.txt (deflated 58%)\n  adding: kaggle/working/wandb/latest-run/files/conda-environment.yaml (deflated 66%)\n  adding: kaggle/working/wandb/latest-run/run-h800x6ur.wandb\n\tzip warning:  file size changed while zipping /kaggle/working/wandb/latest-run/run-h800x6ur.wandb\n (deflated 83%)\n  adding: kaggle/working/wandb/latest-run/logs/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/logs/debug-internal.log (deflated 95%)\n  adding: kaggle/working/wandb/latest-run/logs/debug.log (deflated 76%)\n  adding: kaggle/working/wandb/latest-run/tmp/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/tmp/code/ (stored 0%)\n  adding: kaggle/working/wandb/debug-internal.log (deflated 95%)\n  adding: kaggle/working/wandb/debug.log (deflated 76%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/ (stored 0%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/files/ (stored 0%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/files/config.yaml (deflated 79%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/files/wandb-summary.json (deflated 66%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/files/output.log (deflated 96%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/files/wandb-metadata.json (deflated 60%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/files/requirements.txt (deflated 58%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/files/conda-environment.yaml (deflated 66%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/logs/ (stored 0%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/logs/debug-internal.log (deflated 94%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/logs/debug.log (deflated 74%)\n  adding: kaggle/working/wandb/run-20230926_130104-0flpqdir/run-0flpqdir.wandb (deflated 85%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r model_tasknet_adapter_6epoch.zip /kaggle/working/tasknet_6epochs-adapter","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:42:54.009558Z","iopub.execute_input":"2023-09-26T17:42:54.009999Z","iopub.status.idle":"2023-09-26T17:42:55.269620Z","shell.execute_reply.started":"2023-09-26T17:42:54.009961Z","shell.execute_reply":"2023-09-26T17:42:55.265158Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n  adding: kaggle/working/tasknet_6epochs-adapter/ (stored 0%)\n  adding: kaggle/working/tasknet_6epochs-adapter/pytorch_model.bin (deflated 7%)\n  adding: kaggle/working/tasknet_6epochs-adapter/config.json (deflated 74%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install xformers","metadata":{"execution":{"iopub.status.idle":"2023-09-26T16:21:08.697232Z","shell.execute_reply.started":"2023-09-26T16:17:42.942453Z","shell.execute_reply":"2023-09-26T16:21:08.695600Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchdata 0.6.0 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cmake-3.27.5 lit-17.0.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0 xformers-0.0.21\n","output_type":"stream"}]},{"cell_type":"code","source":"p = trainer.pipeline()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:28:34.117734Z","iopub.execute_input":"2023-10-01T11:28:34.118097Z","iopub.status.idle":"2023-10-01T11:28:34.438152Z","shell.execute_reply.started":"2023-10-01T11:28:34.118069Z","shell.execute_reply":"2023-10-01T11:28:34.437000Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\npip install xformers.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = pd.read_json(path_or_buf=\"/kaggle/input/indoml-massive-dataset/public_dat/massive_test.data.jsonl\", lines=True)\ntest_data = test_data.loc[:, [\"indoml_id\", \"utt\"]]\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:30:10.719368Z","iopub.execute_input":"2023-10-01T11:30:10.719800Z","iopub.status.idle":"2023-10-01T11:30:15.579996Z","shell.execute_reply.started":"2023-10-01T11:30:10.719770Z","shell.execute_reply":"2023-10-01T11:30:15.578696Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"  indoml_id                                             utt\n0   af-ZA|0            maak my wakker om vyf v. m. die week\n1   af-ZA|3                                            stil\n2   af-ZA|8                   pienk is al wat ons nodig het\n3  af-ZA|14                       en die donkerte het geval\n4  af-ZA|19  janneman skakel die ligte af in die slaapkamer","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>indoml_id</th>\n      <th>utt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>af-ZA|0</td>\n      <td>maak my wakker om vyf v. m. die week</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>af-ZA|3</td>\n      <td>stil</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>af-ZA|8</td>\n      <td>pienk is al wat ons nodig het</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>af-ZA|14</td>\n      <td>en die donkerte het geval</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>af-ZA|19</td>\n      <td>janneman skakel die ligte af in die slaapkamer</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\np = pipeline(\"text-classification\", model = \"/kaggle/input/indoml-6epochs-withtokenizer/kaggle/working/tasknet_6epochs\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T16:30:32.734971Z","iopub.execute_input":"2023-09-30T16:30:32.735491Z","iopub.status.idle":"2023-09-30T16:30:57.886368Z","shell.execute_reply.started":"2023-09-30T16:30:32.735448Z","shell.execute_reply":"2023-09-30T16:30:57.885511Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nSome weights of the model checkpoint at /kaggle/input/indoml-6epochs-withtokenizer/kaggle/working/tasknet_6epochs were not used when initializing DebertaV2ForSequenceClassification: ['deberta.encoder.layer.8.output.LayerNorm.L1.weight', 'deberta.embeddings.LayerNorm.L1.bias', 'deberta.encoder.layer.4.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.10.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.0.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.2.output.LayerNorm.L1.bias', 'deberta.encoder.layer.0.output.LayerNorm.LN.weight', 'deberta.encoder.LayerNorm.LN.weight', 'deberta.encoder.layer.1.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.3.output.LayerNorm.gates', 'deberta.encoder.layer.5.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.2.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.1.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.2.attention.output.LayerNorm.gates', 'deberta.encoder.layer.6.output.LayerNorm.LN.weight', 'deberta.encoder.layer.8.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.gates', 'deberta.encoder.layer.11.output.LayerNorm.LN.bias', 'deberta.encoder.layer.1.output.LayerNorm.LN.bias', 'deberta.encoder.layer.7.attention.output.LayerNorm.gates', 'deberta.encoder.layer.4.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.9.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.L1.bias', 'deberta.encoder.LayerNorm.L1.bias', 'deberta.encoder.layer.7.output.LayerNorm.LN.weight', 'deberta.encoder.layer.8.attention.output.LayerNorm.gates', 'deberta.encoder.layer.11.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.2.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.9.attention.output.LayerNorm.gates', 'deberta.encoder.layer.9.output.LayerNorm.L1.bias', 'deberta.encoder.layer.8.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.10.output.LayerNorm.L1.weight', 'deberta.encoder.layer.2.output.LayerNorm.gates', 'deberta.encoder.layer.9.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.5.attention.output.LayerNorm.gates', 'deberta.encoder.layer.8.output.LayerNorm.L1.bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.2.output.LayerNorm.LN.bias', 'deberta.encoder.layer.8.output.LayerNorm.LN.weight', 'deberta.embeddings.LayerNorm.LN.weight', 'deberta.encoder.layer.4.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.10.output.LayerNorm.LN.bias', 'deberta.encoder.layer.3.attention.output.LayerNorm.gates', 'deberta.embeddings.LayerNorm.LN.bias', 'deberta.encoder.layer.8.output.LayerNorm.gates', 'deberta.encoder.layer.6.output.LayerNorm.gates', 'deberta.encoder.layer.6.output.LayerNorm.LN.bias', 'deberta.encoder.layer.11.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.5.output.LayerNorm.LN.bias', 'deberta.encoder.layer.0.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.6.output.LayerNorm.L1.weight', 'deberta.encoder.layer.7.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.7.output.LayerNorm.L1.weight', 'deberta.encoder.layer.1.output.LayerNorm.L1.bias', 'deberta.encoder.layer.2.output.LayerNorm.LN.weight', 'deberta.encoder.layer.3.output.LayerNorm.L1.bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.gates', 'deberta.encoder.layer.8.attention.output.LayerNorm.LN.weight', 'deberta.embeddings.LayerNorm.L1.weight', 'deberta.encoder.layer.7.output.LayerNorm.gates', 'deberta.encoder.layer.9.output.LayerNorm.LN.bias', 'deberta.encoder.layer.6.output.LayerNorm.L1.bias', 'deberta.encoder.layer.7.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.9.output.LayerNorm.L1.weight', 'deberta.encoder.layer.11.attention.output.LayerNorm.gates', 'deberta.encoder.layer.4.output.LayerNorm.L1.bias', 'deberta.encoder.layer.0.output.LayerNorm.LN.bias', 'deberta.encoder.layer.5.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.5.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.3.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.4.output.LayerNorm.LN.bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.10.output.LayerNorm.L1.bias', 'deberta.encoder.layer.11.output.LayerNorm.L1.bias', 'deberta.encoder.layer.11.output.LayerNorm.LN.weight', 'deberta.encoder.LayerNorm.L1.weight', 'deberta.encoder.layer.1.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.4.output.LayerNorm.gates', 'deberta.encoder.layer.3.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.3.output.LayerNorm.LN.bias', 'deberta.encoder.layer.10.output.LayerNorm.LN.weight', 'deberta.encoder.layer.5.output.LayerNorm.L1.bias', 'deberta.encoder.layer.1.output.LayerNorm.gates', 'deberta.encoder.layer.4.attention.output.LayerNorm.gates', 'deberta.encoder.layer.0.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.0.output.LayerNorm.L1.weight', 'deberta.encoder.layer.0.output.LayerNorm.gates', 'deberta.encoder.layer.8.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.7.output.LayerNorm.L1.bias', 'deberta.encoder.layer.11.output.LayerNorm.L1.weight', 'deberta.encoder.layer.9.output.LayerNorm.gates', 'deberta.encoder.layer.2.output.LayerNorm.L1.weight', 'deberta.encoder.layer.9.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.11.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.3.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.5.output.LayerNorm.LN.weight', 'deberta.encoder.layer.5.output.LayerNorm.L1.weight', 'deberta.encoder.layer.3.output.LayerNorm.L1.weight', 'deberta.encoder.layer.6.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.2.attention.output.LayerNorm.L1.weight', 'deberta.encoder.LayerNorm.LN.bias', 'deberta.encoder.layer.0.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.1.attention.output.LayerNorm.gates', 'deberta.encoder.layer.4.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.3.attention.output.LayerNorm.L1.bias', 'deberta.encoder.LayerNorm.gates', 'deberta.encoder.layer.11.output.LayerNorm.gates', 'deberta.embeddings.LayerNorm.gates', 'deberta.encoder.layer.9.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.7.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.1.output.LayerNorm.LN.weight', 'deberta.encoder.layer.3.output.LayerNorm.LN.weight', 'deberta.encoder.layer.10.output.LayerNorm.gates', 'deberta.encoder.layer.4.output.LayerNorm.LN.weight', 'deberta.encoder.layer.4.output.LayerNorm.L1.weight', 'deberta.encoder.layer.5.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.1.attention.output.LayerNorm.L1.bias', 'deberta.encoder.layer.9.output.LayerNorm.LN.weight', 'deberta.encoder.layer.2.attention.output.LayerNorm.LN.bias', 'deberta.encoder.layer.0.attention.output.LayerNorm.gates', 'deberta.encoder.layer.11.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.1.output.LayerNorm.L1.weight', 'deberta.encoder.layer.7.output.LayerNorm.LN.bias', 'deberta.encoder.layer.8.output.LayerNorm.LN.bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.10.attention.output.LayerNorm.LN.weight', 'deberta.encoder.layer.0.output.LayerNorm.L1.bias', 'deberta.encoder.layer.7.attention.output.LayerNorm.L1.weight', 'deberta.encoder.layer.5.output.LayerNorm.gates']\n- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/indoml-6epochs-withtokenizer/kaggle/working/tasknet_6epochs and are newly initialized: ['deberta.embeddings.LayerNorm.weight', 'deberta.encoder.layer.6.attention.output.LayerNorm.bias', 'deberta.encoder.layer.5.attention.output.LayerNorm.bias', 'deberta.encoder.layer.3.attention.output.LayerNorm.bias', 'deberta.encoder.layer.0.output.LayerNorm.bias', 'deberta.encoder.layer.6.output.LayerNorm.weight', 'deberta.encoder.layer.11.attention.output.LayerNorm.bias', 'deberta.embeddings.LayerNorm.bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.weight', 'deberta.encoder.layer.8.attention.output.LayerNorm.bias', 'deberta.encoder.layer.1.output.LayerNorm.weight', 'deberta.encoder.layer.9.output.LayerNorm.bias', 'deberta.encoder.LayerNorm.weight', 'deberta.encoder.layer.5.output.LayerNorm.bias', 'deberta.encoder.layer.0.output.LayerNorm.weight', 'deberta.encoder.layer.10.output.LayerNorm.bias', 'deberta.encoder.layer.9.output.LayerNorm.weight', 'deberta.encoder.layer.10.attention.output.LayerNorm.bias', 'deberta.encoder.layer.2.attention.output.LayerNorm.weight', 'deberta.encoder.layer.5.attention.output.LayerNorm.weight', 'deberta.encoder.layer.2.output.LayerNorm.bias', 'deberta.encoder.layer.2.attention.output.LayerNorm.bias', 'deberta.encoder.layer.3.attention.output.LayerNorm.weight', 'deberta.encoder.layer.1.output.LayerNorm.bias', 'deberta.encoder.layer.4.output.LayerNorm.weight', 'deberta.encoder.layer.11.output.LayerNorm.bias', 'deberta.encoder.layer.4.attention.output.LayerNorm.bias', 'deberta.encoder.layer.1.attention.output.LayerNorm.weight', 'deberta.encoder.layer.7.attention.output.LayerNorm.bias', 'deberta.encoder.layer.5.output.LayerNorm.weight', 'deberta.encoder.layer.8.output.LayerNorm.weight', 'deberta.encoder.layer.3.output.LayerNorm.weight', 'deberta.encoder.LayerNorm.bias', 'deberta.encoder.layer.7.output.LayerNorm.weight', 'deberta.encoder.layer.0.attention.output.LayerNorm.weight', 'deberta.encoder.layer.3.output.LayerNorm.bias', 'deberta.encoder.layer.4.attention.output.LayerNorm.weight', 'deberta.encoder.layer.11.attention.output.LayerNorm.weight', 'deberta.encoder.layer.9.attention.output.LayerNorm.weight', 'deberta.encoder.layer.1.attention.output.LayerNorm.bias', 'deberta.encoder.layer.7.attention.output.LayerNorm.weight', 'deberta.encoder.layer.7.output.LayerNorm.bias', 'deberta.encoder.layer.10.output.LayerNorm.weight', 'deberta.encoder.layer.9.attention.output.LayerNorm.bias', 'deberta.encoder.layer.0.attention.output.LayerNorm.bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.weight', 'deberta.encoder.layer.11.output.LayerNorm.weight', 'deberta.encoder.layer.4.output.LayerNorm.bias', 'deberta.encoder.layer.8.output.LayerNorm.bias', 'deberta.encoder.layer.8.attention.output.LayerNorm.weight', 'deberta.encoder.layer.2.output.LayerNorm.weight', 'deberta.encoder.layer.6.output.LayerNorm.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nXformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\npip install xformers.\n","output_type":"stream"}]},{"cell_type":"code","source":"p(test_data.iloc[2:3, 1].values[0])[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:30:30.116820Z","iopub.execute_input":"2023-10-01T11:30:30.117220Z","iopub.status.idle":"2023-10-01T11:30:30.161090Z","shell.execute_reply.started":"2023-10-01T11:30:30.117172Z","shell.execute_reply":"2023-10-01T11:30:30.159938Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"{'label': 'audio_volume_other', 'score': 0.44328534603118896}"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.save(models, \"/kaggle/working/model.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T12:37:54.662045Z","iopub.execute_input":"2023-10-01T12:37:54.662406Z","iopub.status.idle":"2023-10-01T12:37:58.938803Z","shell.execute_reply.started":"2023-10-01T12:37:54.662380Z","shell.execute_reply":"2023-10-01T12:37:58.936857Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"models.state_dict","metadata":{"execution":{"iopub.status.busy":"2023-10-01T12:38:25.445458Z","iopub.execute_input":"2023-10-01T12:38:25.445858Z","iopub.status.idle":"2023-10-01T12:38:25.467818Z","shell.execute_reply.started":"2023-10-01T12:38:25.445827Z","shell.execute_reply":"2023-10-01T12:38:25.466684Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"<bound method Module.state_dict of Model(\n  (shared_encoder): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(251000, 768, padding_idx=0)\n      (LayerNorm): ConditionalLayerNorm(\n        (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n        (L1): Linear(in_features=96, out_features=1536, bias=True)\n        (sigmoid): Sigmoid()\n      )\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): ConditionalLayerNorm(\n                (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n                (L1): Linear(in_features=96, out_features=1536, bias=True)\n                (sigmoid): Sigmoid()\n              )\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): ConditionalLayerNorm(\n              (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (L1): Linear(in_features=96, out_features=1536, bias=True)\n              (sigmoid): Sigmoid()\n            )\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): ConditionalLayerNorm(\n        (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n        (L1): Linear(in_features=96, out_features=1536, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (shared_pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): StableDropout()\n  )\n  (task_models_list): ModuleList(\n    (0): DebertaV2ForSequenceClassification(\n      (deberta): DebertaV2Model(\n        (embeddings): DebertaV2Embeddings(\n          (word_embeddings): Embedding(251000, 768, padding_idx=0)\n          (LayerNorm): ConditionalLayerNorm(\n            (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (L1): Linear(in_features=96, out_features=1536, bias=True)\n            (sigmoid): Sigmoid()\n          )\n          (dropout): StableDropout()\n        )\n        (encoder): DebertaV2Encoder(\n          (layer): ModuleList(\n            (0-11): 12 x DebertaV2Layer(\n              (attention): DebertaV2Attention(\n                (self): DisentangledSelfAttention(\n                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (pos_dropout): StableDropout()\n                  (dropout): StableDropout()\n                )\n                (output): DebertaV2SelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): ConditionalLayerNorm(\n                    (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n                    (L1): Linear(in_features=96, out_features=1536, bias=True)\n                    (sigmoid): Sigmoid()\n                  )\n                  (dropout): StableDropout()\n                )\n              )\n              (intermediate): DebertaV2Intermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): DebertaV2Output(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): ConditionalLayerNorm(\n                  (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n                  (L1): Linear(in_features=96, out_features=1536, bias=True)\n                  (sigmoid): Sigmoid()\n                )\n                (dropout): StableDropout()\n              )\n            )\n          )\n          (rel_embeddings): Embedding(512, 768)\n          (LayerNorm): ConditionalLayerNorm(\n            (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (L1): Linear(in_features=96, out_features=1536, bias=True)\n            (sigmoid): Sigmoid()\n          )\n        )\n      )\n      (pooler): ContextPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): StableDropout()\n      )\n      (classifier): Linear(in_features=768, out_features=60, bias=True)\n      (dropout): StableDropout()\n    )\n    (1): DebertaV2ForTokenClassification(\n      (deberta): DebertaV2Model(\n        (embeddings): DebertaV2Embeddings(\n          (word_embeddings): Sequential(\n            (0): Embedding(251000, 768, padding_idx=0)\n            (1): CLSEmbedding()\n          )\n          (LayerNorm): ConditionalLayerNorm(\n            (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (L1): Linear(in_features=96, out_features=1536, bias=True)\n            (sigmoid): Sigmoid()\n          )\n          (dropout): StableDropout()\n        )\n        (encoder): DebertaV2Encoder(\n          (layer): ModuleList(\n            (0-11): 12 x DebertaV2Layer(\n              (attention): DebertaV2Attention(\n                (self): DisentangledSelfAttention(\n                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (pos_dropout): StableDropout()\n                  (dropout): StableDropout()\n                )\n                (output): DebertaV2SelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): ConditionalLayerNorm(\n                    (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n                    (L1): Linear(in_features=96, out_features=1536, bias=True)\n                    (sigmoid): Sigmoid()\n                  )\n                  (dropout): StableDropout()\n                )\n              )\n              (intermediate): DebertaV2Intermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): DebertaV2Output(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): ConditionalLayerNorm(\n                  (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n                  (L1): Linear(in_features=96, out_features=1536, bias=True)\n                  (sigmoid): Sigmoid()\n                )\n                (dropout): StableDropout()\n              )\n            )\n          )\n          (rel_embeddings): Embedding(512, 768)\n          (LayerNorm): ConditionalLayerNorm(\n            (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (L1): Linear(in_features=96, out_features=1536, bias=True)\n            (sigmoid): Sigmoid()\n          )\n        )\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n      (classifier): Linear(in_features=768, out_features=111, bias=True)\n      (auto): DebertaV2Model(\n        (embeddings): DebertaV2Embeddings(\n          (word_embeddings): Sequential(\n            (0): Embedding(251000, 768, padding_idx=0)\n            (1): CLSEmbedding()\n          )\n          (LayerNorm): ConditionalLayerNorm(\n            (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (L1): Linear(in_features=96, out_features=1536, bias=True)\n            (sigmoid): Sigmoid()\n          )\n          (dropout): StableDropout()\n        )\n        (encoder): DebertaV2Encoder(\n          (layer): ModuleList(\n            (0-11): 12 x DebertaV2Layer(\n              (attention): DebertaV2Attention(\n                (self): DisentangledSelfAttention(\n                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (pos_dropout): StableDropout()\n                  (dropout): StableDropout()\n                )\n                (output): DebertaV2SelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): ConditionalLayerNorm(\n                    (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n                    (L1): Linear(in_features=96, out_features=1536, bias=True)\n                    (sigmoid): Sigmoid()\n                  )\n                  (dropout): StableDropout()\n                )\n              )\n              (intermediate): DebertaV2Intermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): DebertaV2Output(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): ConditionalLayerNorm(\n                  (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n                  (L1): Linear(in_features=96, out_features=1536, bias=True)\n                  (sigmoid): Sigmoid()\n                )\n                (dropout): StableDropout()\n              )\n            )\n          )\n          (rel_embeddings): Embedding(512, 768)\n          (LayerNorm): ConditionalLayerNorm(\n            (LN): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (L1): Linear(in_features=96, out_features=1536, bias=True)\n            (sigmoid): Sigmoid()\n          )\n        )\n      )\n    )\n  )\n)>"},"metadata":{}}]},{"cell_type":"code","source":"trainer","metadata":{"execution":{"iopub.status.busy":"2023-10-01T12:41:58.192639Z","iopub.execute_input":"2023-10-01T12:41:58.193790Z","iopub.status.idle":"2023-10-01T12:41:58.205820Z","shell.execute_reply.started":"2023-10-01T12:41:58.193748Z","shell.execute_reply":"2023-10-01T12:41:58.204747Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"<tasknet.models.Trainer at 0x7a86f4c6a890>"},"metadata":{}}]},{"cell_type":"code","source":"import json\noutput_file = 'output.jsonl'\n\nwith open(output_file, 'w') as jsonl_file:\n    for index, row in test_data.iterrows():\n        id_value = row['indoml_id']\n        utterance = row['utt']\n        # Process the utterance using the model\n        result = p(utterance.encode('utf-8').decode('utf-8'))[0][\"label\"]\n        \n        # Create a dictionary for JSONL entry\n        json_entry = {'indoml_id': id_value, 'intent': result}\n        \n        # Write the JSON entry to the JSONL file\n        jsonl_file.write(json.dumps(json_entry) + '\\n')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:30:44.086632Z","iopub.execute_input":"2023-10-01T11:30:44.087023Z","iopub.status.idle":"2023-10-01T12:28:43.307063Z","shell.execute_reply.started":"2023-10-01T11:30:44.086998Z","shell.execute_reply":"2023-10-01T12:28:43.305666Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T12:31:05.308794Z","iopub.execute_input":"2023-10-01T12:31:05.309236Z","iopub.status.idle":"2023-10-01T12:31:08.089531Z","shell.execute_reply.started":"2023-10-01T12:31:05.309209Z","shell.execute_reply":"2023-10-01T12:31:08.088439Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"1148"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"multi_task/\")","metadata":{"execution":{"iopub.status.busy":"2023-09-24T07:37:58.227090Z","iopub.execute_input":"2023-09-24T07:37:58.228156Z","iopub.status.idle":"2023-09-24T07:38:00.844692Z","shell.execute_reply.started":"2023-09-24T07:37:58.228118Z","shell.execute_reply":"2023-09-24T07:38:00.839321Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check = load_dataset(\"glue\", \"ax\")\ncheck[\"test\"].features[\"label\"]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:33:37.517917Z","iopub.execute_input":"2023-09-23T06:33:37.519333Z","iopub.status.idle":"2023-09-23T06:33:37.878134Z","shell.execute_reply.started":"2023-09-23T06:33:37.519264Z","shell.execute_reply":"2023-09-23T06:33:37.877078Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"305c294cea6b4af481b0ba04a1b6d51a"}},"metadata":{}},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"ClassLabel(num_classes=3, names=['entailment', 'neutral', 'contradiction'], id=None)"},"metadata":{}}]},{"cell_type":"code","source":"dataset_target[\"train\"].features[\"intent\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:34:15.744467Z","iopub.execute_input":"2023-09-23T06:34:15.744836Z","iopub.status.idle":"2023-09-23T06:34:15.754701Z","shell.execute_reply.started":"2023-09-23T06:34:15.744806Z","shell.execute_reply":"2023-09-23T06:34:15.753319Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"ClassLabel(num_classes=60, names=['alarm_query', 'alarm_remove', 'alarm_set', 'audio_volume_down', 'audio_volume_mute', 'audio_volume_other', 'audio_volume_up', 'calendar_query', 'calendar_remove', 'calendar_set', 'cooking_query', 'cooking_recipe', 'datetime_convert', 'datetime_query', 'email_addcontact', 'email_query', 'email_querycontact', 'email_sendemail', 'general_greet', 'general_joke', 'general_quirky', 'iot_cleaning', 'iot_coffee', 'iot_hue_lightchange', 'iot_hue_lightdim', 'iot_hue_lightoff', 'iot_hue_lighton', 'iot_hue_lightup', 'iot_wemo_off', 'iot_wemo_on', 'lists_createoradd', 'lists_query', 'lists_remove', 'music_dislikeness', 'music_likeness', 'music_query', 'music_settings', 'news_query', 'play_audiobook', 'play_game', 'play_music', 'play_podcasts', 'play_radio', 'qa_currency', 'qa_definition', 'qa_factoid', 'qa_maths', 'qa_stock', 'recommendation_events', 'recommendation_locations', 'recommendation_movies', 'social_post', 'social_query', 'takeaway_order', 'takeaway_query', 'transport_query', 'transport_taxi', 'transport_ticket', 'transport_traffic', 'weather_query'], id=None)"},"metadata":{}}]},{"cell_type":"code","source":"model_2 =  tn.load_pipeline(\"/kaggle/working/multi_task\",\"intent_classification\", adapt_task_embedding=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T08:44:24.542277Z","iopub.execute_input":"2023-09-24T08:44:24.542668Z","iopub.status.idle":"2023-09-24T08:44:25.080653Z","shell.execute_reply.started":"2023-09-24T08:44:24.542639Z","shell.execute_reply":"2023-09-24T08:44:25.078055Z"},"trusted":true},"execution_count":70,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 model_2 =  tn.load_pipeline(\u001b[33m\"\u001b[0m\u001b[33m/kaggle/working/multi_task\u001b[0m\u001b[33m\"\u001b[0m,\u001b[33m\"\u001b[0m\u001b[33mintent_classification\u001b[0m\u001b[33m\"\u001b[0m, adapt_     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/tasknet/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m198\u001b[0m in \u001b[92mload_pipeline\u001b[0m                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mtasksource\u001b[0m                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m:                                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mImportError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mRequires tasksource.\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m pip install tasksource\u001b[0m\u001b[33m\"\u001b[0m)                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m198 \u001b[2m│   \u001b[0mtask = tasksource.load_task(task_name, multilingual=multilingual)                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   \u001b[0mmodel = AutoModelForSequenceClassification.from_pretrained(                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_name, ignore_mismatched_sizes=\u001b[94mTrue\u001b[0m                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/tasksource/\u001b[0m\u001b[1;33maccess.py\u001b[0m:\u001b[94m102\u001b[0m in \u001b[92mload_task\u001b[0m                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   \u001b[0mquery = dict_of(\u001b[96mid\u001b[0m, dataset_name, config_name, task_name,preprocessing_name)           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   \u001b[0mquery = {k:v \u001b[94mfor\u001b[0m k,v \u001b[95min\u001b[0m query.items() \u001b[94mif\u001b[0m v}                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   \u001b[0m_tasks = (lmtasks \u001b[94mif\u001b[0m multilingual \u001b[94melse\u001b[0m tasks)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m102 \u001b[2m│   \u001b[0mpreprocessing = load_preprocessing(_tasks, **query)                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   \u001b[0mdataset = load_dataset(preprocessing.dataset_name, preprocessing.config_name, **load   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m\u001b[2m│   \u001b[0mdataset= preprocessing(dataset,max_rows, max_rows_eval)                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   \u001b[0mdataset.task_type = preprocessing.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/tasksource/\u001b[0m\u001b[1;33maccess.py\u001b[0m:\u001b[94m90\u001b[0m in \u001b[92mload_preprocessing\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 87 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 88 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mload_preprocessing\u001b[0m(tasks=tasks, **kwargs):                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 89 \u001b[0m\u001b[2m│   \u001b[0m_tasks_df = list_tasks(multilingual=tasks==lmtasks)                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 90 \u001b[2m│   \u001b[0my = _tasks_df.copy().query(dict_to_query(**kwargs)).iloc[\u001b[94m0\u001b[0m]                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 91 \u001b[0m\u001b[2m│   \u001b[0mpreprocessing= copy.copy(\u001b[96mgetattr\u001b[0m(tasks, y.preprocessing_name))                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m c \u001b[95min\u001b[0m \u001b[33m'\u001b[0m\u001b[33mdataset_name\u001b[0m\u001b[33m'\u001b[0m,\u001b[33m'\u001b[0m\u001b[33mconfig_name\u001b[0m\u001b[33m'\u001b[0m:                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(\u001b[96mgetattr\u001b[0m(preprocessing,c), \u001b[96mstr\u001b[0m):                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mindexing.py\u001b[0m:\u001b[94m1073\u001b[0m in \u001b[92m__getitem__\u001b[0m              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1070 \u001b[0m\u001b[2m│   │   │   \u001b[0maxis = \u001b[96mself\u001b[0m.axis \u001b[95mor\u001b[0m \u001b[94m0\u001b[0m                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1071 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1072 \u001b[0m\u001b[2m│   │   │   \u001b[0mmaybe_callable = com.apply_if_callable(key, \u001b[96mself\u001b[0m.obj)                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1073 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._getitem_axis(maybe_callable, axis=axis)                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1074 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1075 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_is_scalar_access\u001b[0m(\u001b[96mself\u001b[0m, key: \u001b[96mtuple\u001b[0m):                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1076 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mNotImplementedError\u001b[0m()                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mindexing.py\u001b[0m:\u001b[94m1625\u001b[0m in \u001b[92m_getitem_axis\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1622 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mCannot index by location index with a non-integer key\u001b[0m\u001b[33m\"\u001b[0m)  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1623 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1624 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# validate the location\u001b[0m                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1625 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._validate_integer(key, axis)                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1626 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1627 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.obj._ixs(key, axis=axis)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1628 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mindexing.py\u001b[0m:\u001b[94m1557\u001b[0m in \u001b[92m_validate_integer\u001b[0m        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1554 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1555 \u001b[0m\u001b[2m│   │   \u001b[0mlen_axis = \u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.obj._get_axis(axis))                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1556 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m key >= len_axis \u001b[95mor\u001b[0m key < -len_axis:                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1557 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mIndexError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33msingle positional indexer is out-of-bounds\u001b[0m\u001b[33m\"\u001b[0m)                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1558 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1559 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# -------------------------------------------------------------------\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1560 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mIndexError: \u001b[0msingle positional indexer is out-of-bounds\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 model_2 =  tn.load_pipeline(<span style=\"color: #808000; text-decoration-color: #808000\">\"/kaggle/working/multi_task\"</span>,<span style=\"color: #808000; text-decoration-color: #808000\">\"intent_classification\"</span>, adapt_     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/tasknet/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">198</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_pipeline</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">tasksource</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span>:                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ImportError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Requires tasksource.\\n pip install tasksource\"</span>)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>198 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>task = tasksource.load_task(task_name, multilingual=multilingual)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model = AutoModelForSequenceClassification.from_pretrained(                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model_name, ignore_mismatched_sizes=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/tasksource/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">access.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">102</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_task</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>query = dict_of(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">id</span>, dataset_name, config_name, task_name,preprocessing_name)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>query = {k:v <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k,v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> query.items() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> v}                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">101 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_tasks = (lmtasks <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> multilingual <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> tasks)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>102 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>preprocessing = load_preprocessing(_tasks, **query)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">103 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>dataset = load_dataset(preprocessing.dataset_name, preprocessing.config_name, **load   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">104 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>dataset= preprocessing(dataset,max_rows, max_rows_eval)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>dataset.task_type = preprocessing.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/tasksource/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">access.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">90</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_preprocessing</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 87 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 88 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_preprocessing</span>(tasks=tasks, **kwargs):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 89 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_tasks_df = list_tasks(multilingual=tasks==lmtasks)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 90 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>y = _tasks_df.copy().query(dict_to_query(**kwargs)).iloc[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 91 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>preprocessing= copy.copy(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(tasks, y.preprocessing_name))                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 92 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> c <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #808000; text-decoration-color: #808000\">'dataset_name'</span>,<span style=\"color: #808000; text-decoration-color: #808000\">'config_name'</span>:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(preprocessing,c), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">indexing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1073</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1070 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>axis = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.axis <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1071 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1072 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>maybe_callable = com.apply_if_callable(key, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.obj)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1073 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._getitem_axis(maybe_callable, axis=axis)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1074 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_is_scalar_access</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, key: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1076 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">NotImplementedError</span>()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">indexing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1625</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_getitem_axis</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1622 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Cannot index by location index with a non-integer key\"</span>)  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1623 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1624 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># validate the location</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1625 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._validate_integer(key, axis)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1626 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1627 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.obj._ixs(key, axis=axis)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1628 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">indexing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1557</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_validate_integer</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1554 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1555 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>len_axis = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.obj._get_axis(axis))                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1556 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> key &gt;= len_axis <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> key &lt; -len_axis:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1557 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">IndexError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"single positional indexer is out-of-bounds\"</span>)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1558 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1559 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># -------------------------------------------------------------------</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1560 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndexError: </span>single positional indexer is out-of-bounds\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"from tasksource import list_tasks, load_task\ndf = list_tasks(multilingual=False) # takes some time\n\nfor id in df[df.task_type==\"Classification\"].id:\n    print(id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load pretrained slot method - failed","metadata":{}},{"cell_type":"code","source":"id2label = {\n    0: \"datetime_query\",\n    1: \"iot_hue_lightchange\",\n    2: \"transport_ticket\",\n    3: \"takeaway_query\",\n    4: \"qa_stock\",\n    5: \"general_greet\",\n    6: \"recommendation_events\",\n    7: \"music_dislikeness\",\n    8: \"iot_wemo_off\",\n    9: \"cooking_recipe\",\n    10: \"qa_currency\",\n    11: \"transport_traffic\",\n    12: \"general_quirky\",\n    13: \"weather_query\",\n    14: \"audio_volume_up\",\n    15: \"email_addcontact\",\n    16: \"takeaway_order\",\n    17: \"email_querycontact\",\n    18: \"iot_hue_lightup\",\n    19: \"recommendation_locations\",\n    20: \"play_audiobook\",\n    21: \"lists_createoradd\",\n    22: \"news_query\",\n    23: \"alarm_query\",\n    24: \"iot_wemo_on\",\n    25: \"general_joke\",\n    26: \"qa_definition\",\n    27: \"social_query\",\n    28: \"music_settings\",\n    29: \"audio_volume_other\",\n    30: \"calendar_remove\",\n    31: \"iot_hue_lightdim\",\n    32: \"calendar_query\",\n    33: \"email_sendemail\",\n    34: \"iot_cleaning\",\n    35: \"audio_volume_down\",\n    36: \"play_radio\",\n    37: \"cooking_query\",\n    38: \"datetime_convert\",\n    39: \"qa_maths\",\n    40: \"iot_hue_lightoff\",\n    41: \"iot_hue_lighton\",\n    42: \"transport_query\",\n    43: \"music_likeness\",\n    44: \"email_query\",\n    45: \"play_music\",\n    46: \"audio_volume_mute\",\n    47: \"social_post\",\n    48: \"alarm_set\",\n    49: \"qa_factoid\",\n    50: \"calendar_set\",\n    51: \"play_game\",\n    52: \"alarm_remove\",\n    53: \"lists_remove\",\n    54: \"transport_taxi\",\n    55: \"recommendation_movies\",\n    56: \"iot_coffee\",\n    57: \"music_query\",\n    58: \"play_podcasts\",\n    59: \"lists_query\"\n}\nlabel2id={'datetime_query': 0, 'iot_hue_lightchange': 1, 'transport_ticket': 2, 'takeaway_query': 3, 'qa_stock': 4, 'general_greet': 5, 'recommendation_events': 6, 'music_dislikeness': 7, 'iot_wemo_off': 8, 'cooking_recipe': 9, 'qa_currency': 10, 'transport_traffic': 11, 'general_quirky': 12, 'weather_query': 13, 'audio_volume_up': 14, 'email_addcontact': 15, 'takeaway_order': 16, 'email_querycontact': 17, 'iot_hue_lightup': 18, 'recommendation_locations': 19, 'play_audiobook': 20, 'lists_createoradd': 21, 'news_query': 22, 'alarm_query': 23, 'iot_wemo_on': 24, 'general_joke': 25, 'qa_definition': 26, 'social_query': 27, 'music_settings': 28, 'audio_volume_other': 29, 'calendar_remove': 30, 'iot_hue_lightdim': 31, 'calendar_query': 32, 'email_sendemail': 33, 'iot_cleaning': 34, 'audio_volume_down': 35, 'play_radio': 36, 'cooking_query': 37, 'datetime_convert': 38, 'qa_maths': 39, 'iot_hue_lightoff': 40, 'iot_hue_lighton': 41, 'transport_query': 42, 'music_likeness': 43, 'email_query': 44, 'play_music': 45, 'audio_volume_mute': 46, 'social_post': 47, 'alarm_set': 48, 'qa_factoid': 49, 'calendar_set': 50, 'play_game': 51, 'alarm_remove': 52, 'lists_remove': 53, 'transport_taxi': 54, 'recommendation_movies': 55, 'iot_coffee': 56, 'music_query': 57, 'play_podcasts': 58, 'lists_query': 59}\n","metadata":{"execution":{"iopub.status.busy":"2023-09-20T03:46:40.628303Z","iopub.execute_input":"2023-09-20T03:46:40.629114Z","iopub.status.idle":"2023-09-20T03:46:40.645597Z","shell.execute_reply.started":"2023-09-20T03:46:40.629077Z","shell.execute_reply":"2023-09-20T03:46:40.644536Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained(\"cartesinus/xlm-r-base-amazon-massive-slot\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T15:59:30.623092Z","iopub.execute_input":"2023-09-25T15:59:30.623895Z","iopub.status.idle":"2023-09-25T15:59:33.679482Z","shell.execute_reply.started":"2023-09-25T15:59:30.623853Z","shell.execute_reply":"2023-09-25T15:59:33.678441Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b3d4badf79e4a62aa3d2594f75967dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adcf39a98b794e01b112dade2c14d560"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f0dce8114d64b93a6437438d8e58283"}},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"cartesinus/xlm-r-base-amazon-massive-slot\", num_labels = 60)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T15:59:37.036058Z","iopub.execute_input":"2023-09-25T15:59:37.036435Z","iopub.status.idle":"2023-09-25T16:04:52.372365Z","shell.execute_reply.started":"2023-09-25T15:59:37.036405Z","shell.execute_reply":"2023-09-25T16:04:52.371486Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/6.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"869ebd65e7e14e05a4ebc7ac0376da44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40fdba0238b04f089073618cba321219"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at cartesinus/xlm-r-base-amazon-massive-slot were not used when initializing XLMRobertaForSequenceClassification: ['classifier.weight', 'classifier.bias']\n- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cartesinus/xlm-r-base-amazon-massive-slot and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_target = dataset.class_encode_column(\"intent\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:05:04.002655Z","iopub.execute_input":"2023-09-25T16:05:04.003030Z","iopub.status.idle":"2023-09-25T16:05:13.788482Z","shell.execute_reply.started":"2023-09-25T16:05:04.002998Z","shell.execute_reply":"2023-09-25T16:05:13.787469Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/588 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"897fb3f4e04e4f729f0f003f2c238cea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/59 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3239acf7f844802a2f3c4b2027a1798"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/104 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4607416a5fe4ab5a8dacd1904910371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/11 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76cdd90364ec4b268893cd5232737f1b"}},"metadata":{}}]},{"cell_type":"code","source":"dataset_target[\"train\"][\"intent\"][:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:05:16.944721Z","iopub.execute_input":"2023-09-25T16:05:16.945124Z","iopub.status.idle":"2023-09-25T16:05:17.334335Z","shell.execute_reply.started":"2023-09-25T16:05:16.945090Z","shell.execute_reply":"2023-09-25T16:05:17.333185Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[2, 2, 4, 4, 4, 4, 23, 23, 25, 25]"},"metadata":{}}]},{"cell_type":"code","source":"dataset_target[\"train\"] = dataset_target[\"train\"].rename_column(\"utt\", \"text\")\ndataset_target[\"validation\"] = dataset_target[\"validation\"].rename_column(\"utt\", \"text\")\ndataset_target[\"train\"] = dataset_target[\"train\"].rename_column(\"intent\", \"labels\")\ndataset_target[\"validation\"] = dataset_target[\"validation\"].rename_column(\"intent\", \"labels\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:05:20.633123Z","iopub.execute_input":"2023-09-25T16:05:20.633732Z","iopub.status.idle":"2023-09-25T16:05:20.654491Z","shell.execute_reply.started":"2023-09-25T16:05:20.633698Z","shell.execute_reply":"2023-09-25T16:05:20.653574Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"dataset_target","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:05:24.945361Z","iopub.execute_input":"2023-09-25T16:05:24.945747Z","iopub.status.idle":"2023-09-25T16:05:24.952773Z","shell.execute_reply.started":"2023-09-25T16:05:24.945714Z","shell.execute_reply":"2023-09-25T16:05:24.951636Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['indoml_id', 'text', 'labels', '__index_level_0__'],\n        num_rows: 587214\n    })\n    validation: Dataset({\n        features: ['indoml_id', 'text', 'labels', '__index_level_0__'],\n        num_rows: 103683\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, XLMRobertaForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained(\"cartesinus/xlm-r-base-amazon-massive-slot\")\nmodel = XLMRobertaForSequenceClassification.from_pretrained(\"cartesinus/xlm-r-base-amazon-massive-slot\", problem_type=\"multi_label_classification\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-20T03:46:55.525659Z","iopub.execute_input":"2023-09-20T03:46:55.526022Z","iopub.status.idle":"2023-09-20T03:47:19.124489Z","shell.execute_reply.started":"2023-09-20T03:46:55.525992Z","shell.execute_reply":"2023-09-20T03:47:19.123459Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efef2260db154570b037560fed643632"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"630dd7ab479b4349a1021b3f7718a4f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f02095bc06e49468517a177ce21b3b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/6.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"096deb7b59064b9e99dee3ad70928b05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b95afb6953e14ae4afc14a0a78158764"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at cartesinus/xlm-r-base-amazon-massive-slot were not used when initializing XLMRobertaForSequenceClassification: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cartesinus/xlm-r-base-amazon-massive-slot and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_function(examples):\n\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\n\n# tokenized_datasets = dataset.map(tokenize_function)\n# small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n\ntokenized_train = dataset_target[\"train\"].map(tokenize_function, batched=True)\ntokenized_valid = dataset_target[\"validation\"].map(tokenize_function, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:05:37.526689Z","iopub.execute_input":"2023-09-25T16:05:37.527055Z","iopub.status.idle":"2023-09-25T16:09:03.550383Z","shell.execute_reply.started":"2023-09-25T16:05:37.527027Z","shell.execute_reply":"2023-09-25T16:09:03.549376Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/588 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81e524e60ffe440d82cd5d0ddf0e7e90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/104 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93a92c181af641699358d8192983b91f"}},"metadata":{}}]},{"cell_type":"code","source":"small_train_dataset = inputs[\"train\"].shuffle(seed=42).select(range(5000))\nsmall_eval_dataset = inputs[\"valid\"].shuffle(seed=42).select(range(1000))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:09:08.870025Z","iopub.execute_input":"2023-09-25T16:09:08.870443Z","iopub.status.idle":"2023-09-25T16:09:09.802398Z","shell.execute_reply.started":"2023-09-25T16:09:08.870411Z","shell.execute_reply":"2023-09-25T16:09:09.799236Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 small_train_dataset = inputs[\u001b[33m\"\u001b[0m\u001b[33mtrain\u001b[0m\u001b[33m\"\u001b[0m].shuffle(seed=\u001b[94m42\u001b[0m).select(\u001b[96mrange\u001b[0m(\u001b[94m5000\u001b[0m))                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0msmall_eval_dataset = inputs[\u001b[33m\"\u001b[0m\u001b[33mvalid\u001b[0m\u001b[33m\"\u001b[0m].shuffle(seed=\u001b[94m42\u001b[0m).select(\u001b[96mrange\u001b[0m(\u001b[94m1000\u001b[0m))                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mNameError: \u001b[0mname \u001b[32m'inputs'\u001b[0m is not defined\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 small_train_dataset = inputs[<span style=\"color: #808000; text-decoration-color: #808000\">\"train\"</span>].shuffle(seed=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">42</span>).select(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5000</span>))                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>small_eval_dataset = inputs[<span style=\"color: #808000; text-decoration-color: #808000\">\"valid\"</span>].shuffle(seed=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">42</span>).select(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1000</span>))                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'inputs'</span> is not defined\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"with torch.no_grad():\n    logits = model(**inputs).logits\n\npredicted_class_ids = torch.arange(0, logits.shape[-1])[torch.sigmoid(logits).squeeze(dim=0) > 0.5]\n\n# To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\nnum_labels = len(model.config.id2label)\nmodel = XLMRobertaForSequenceClassification.from_pretrained(\n    \"cartesinus/xlm-r-base-amazon-massive-slot\", num_labels=num_labels, problem_type=\"multi_label_classification\"\n)\n\nlabels = torch.sum(\n    torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1\n).to(torch.float)\nloss = model(**small_train_dataset, labels=labels).loss","metadata":{"execution":{"iopub.status.busy":"2023-09-20T04:04:15.844033Z","iopub.execute_input":"2023-09-20T04:04:15.845016Z","iopub.status.idle":"2023-09-20T04:04:16.065514Z","shell.execute_reply.started":"2023-09-20T04:04:15.844966Z","shell.execute_reply":"2023-09-20T04:04:16.064078Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 2 \u001b[2m│   \u001b[0mlogits = model(**inputs).logits                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mpredicted_class_ids = torch.arange(\u001b[94m0\u001b[0m, logits.shape[-\u001b[94m1\u001b[0m])[torch.sigmoid(logits).squeeze(di    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mXLMRobertaForSequenceClassification.forward\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m got an unexpected keyword argument \u001b[32m'train'\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 2 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>logits = model(**inputs).logits                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>predicted_class_ids = torch.arange(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, logits.shape[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>])[torch.sigmoid(logits).squeeze(di    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">XLMRobertaForSequenceClassification.forward</span><span style=\"font-weight: bold\">()</span> got an unexpected keyword argument <span style=\"color: #008000; text-decoration-color: #008000\">'train'</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2023-09-25T14:21:47.331503Z","iopub.execute_input":"2023-09-25T14:21:47.331879Z","iopub.status.idle":"2023-09-25T14:21:47.386501Z","shell.execute_reply.started":"2023-09-25T14:21:47.331849Z","shell.execute_reply":"2023-09-25T14:21:47.385013Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 tokenized_datasets                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mNameError: \u001b[0mname \u001b[32m'tokenized_datasets'\u001b[0m is not defined\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 tokenized_datasets                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'tokenized_datasets'</span> is not defined\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-09-25T13:40:43.837127Z","iopub.execute_input":"2023-09-25T13:40:43.837507Z","iopub.status.idle":"2023-09-25T13:40:55.478642Z","shell.execute_reply.started":"2023-09-25T13:40:43.837476Z","shell.execute_reply":"2023-09-25T13:40:55.477374Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.6.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments\nimport numpy as np\n\nimport evaluate\ntraining_args = TrainingArguments(output_dir=\"test_trainer\",   \n    num_train_epochs=10,              \n    per_device_train_batch_size=8,  \n    per_device_eval_batch_size=8,  \n    learning_rate=5e-6,\n    seed=42,\n    save_strategy='epoch',\n    evaluation_strategy='epoch',\n\n    load_best_model_at_end=True,\n                                 )\n\n\nmetric = evaluate.load(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:09:31.519911Z","iopub.execute_input":"2023-09-25T16:09:31.520324Z","iopub.status.idle":"2023-09-25T16:09:32.317770Z","shell.execute_reply.started":"2023-09-25T16:09:31.520286Z","shell.execute_reply":"2023-09-25T16:09:32.316780Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f8b1388141a46039708a24738d76424"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n#     print(\"computing\")\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\nfrom sklearn.metrics import accuracy_score, f1_score\n\n# def compute_metrics(pred):\n#     labels = pred.label_ids\n#     pred = pred.predictions.argmax(-1)\n#     f1 = f1_score(labels, pred, average=\"weighted\")\n#     acc = accuracy_score(labels, preds)\n#     return {\"accuracy\": acc, \"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:09:51.072058Z","iopub.execute_input":"2023-09-25T16:09:51.072836Z","iopub.status.idle":"2023-09-25T16:09:51.078658Z","shell.execute_reply.started":"2023-09-25T16:09:51.072798Z","shell.execute_reply":"2023-09-25T16:09:51.077600Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nfrom transformers import Trainer\n\n\n# class CustomTrainer(Trainer):\n#     def compute_loss(self, model, inputs, return_outputs=False):\n#         print(inputs)\n#         labels = inputs.pop(\"labels\")\n#         # forward pass\n#         outputs = model(**inputs)\n#         logits = outputs.get(\"logits\")\n#         # compute custom loss (suppose one has 60 labels with equal weights)\n#         loss_fct = nn.CrossEntropyLoss(weight=torch.ones(60, device=model.device))\n#         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n#         return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2023-09-19T18:27:14.189984Z","iopub.execute_input":"2023-09-19T18:27:14.190432Z","iopub.status.idle":"2023-09-19T18:27:14.201178Z","shell.execute_reply.started":"2023-09-19T18:27:14.190388Z","shell.execute_reply":"2023-09-19T18:27:14.199120Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\ntrainer = Trainer(\n\n    model=model,\n\n    args=training_args,\n\n    train_dataset=tokenized_train.shuffle(seed=42).select(range(10000)),\n\n    eval_dataset=tokenized_valid.shuffle(seed=42).select(range(2000)),\n\n    compute_metrics=compute_metrics,\n\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:09:59.263363Z","iopub.execute_input":"2023-09-25T16:09:59.263941Z","iopub.status.idle":"2023-09-25T16:10:05.433713Z","shell.execute_reply.started":"2023-09-25T16:09:59.263898Z","shell.execute_reply":"2023-09-25T16:10:05.432673Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:10:08.844172Z","iopub.execute_input":"2023-09-25T16:10:08.844882Z","iopub.status.idle":"2023-09-25T16:10:08.849918Z","shell.execute_reply.started":"2023-09-25T16:10:08.844829Z","shell.execute_reply":"2023-09-25T16:10:08.848799Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:10:14.521133Z","iopub.execute_input":"2023-09-25T16:10:14.521872Z","iopub.status.idle":"2023-09-25T16:43:46.643143Z","shell.execute_reply.started":"2023-09-25T16:10:14.521833Z","shell.execute_reply":"2023-09-25T16:43:46.641448Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.11 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230925_161035-za02vw41</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/deewhy/huggingface/runs/za02vw41' target=\"_blank\">young-mountain-33</a></strong> to <a href='https://wandb.ai/deewhy/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/deewhy/huggingface' target=\"_blank\">https://wandb.ai/deewhy/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/deewhy/huggingface/runs/za02vw41' target=\"_blank\">https://wandb.ai/deewhy/huggingface/runs/za02vw41</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3872' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 3872/12500 32:33 < 1:12:36, 1.98 it/s, Epoch 3.10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.055700</td>\n      <td>3.968664</td>\n      <td>0.035000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.121200</td>\n      <td>4.096167</td>\n      <td>0.045500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.696400</td>\n      <td>4.297166</td>\n      <td>0.036500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 trainer.train()                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1645\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1642 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1643 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1644 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1645 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1646 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1647 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1648 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1938\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1935 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_step_begin(args, \u001b[96mself\u001b[0m.state,  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1936 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1937 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.accelerator.accumulate(model):                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1938 \u001b[2m│   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1939 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1940 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1941 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2770\u001b[0m in \u001b[92mtraining_step\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2767 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m amp.scale_loss(loss, \u001b[96mself\u001b[0m.optimizer) \u001b[94mas\u001b[0m scaled_loss:                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2768 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mscaled_loss.backward()                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2769 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2770 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.backward(loss)                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2771 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2772 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m loss.detach() / \u001b[96mself\u001b[0m.args.gradient_accumulation_steps                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2773 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m1821\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1818 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.scaler \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1819 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.scaler.scale(loss).backward(**kwargs)                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1820 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1821 \u001b[2m│   │   │   \u001b[0mloss.backward(**kwargs)                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1822 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1823 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92munscale_gradients\u001b[0m(\u001b[96mself\u001b[0m, optimizer=\u001b[94mNone\u001b[0m):                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1824 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mKeyboardInterrupt\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 trainer.train()                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1645</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1645 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1646 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1647 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1648 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1938</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1935 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_step_begin(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1936 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.accumulate(model):                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1938 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1940 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2770</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2767 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> amp.scale_loss(loss, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> scaled_loss:                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2768 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>scaled_loss.backward()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2769 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2770 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.backward(loss)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2771 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2772 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss.detach() / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.gradient_accumulation_steps                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2773 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1821</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1818 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1819 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.scale(loss).backward(**kwargs)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1820 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1821 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss.backward(**kwargs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1822 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1823 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unscale_gradients</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, optimizer=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1824 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# test_data = data.loc[:, [\"indoml_id\", \"utt\"]]\ntest_data = data.loc[:, [\"indoml_id\", \"utt\"]]","metadata":{"execution":{"iopub.status.busy":"2023-08-10T10:16:59.670055Z","iopub.execute_input":"2023-08-10T10:16:59.670403Z","iopub.status.idle":"2023-08-10T10:16:59.690100Z","shell.execute_reply.started":"2023-08-10T10:16:59.670371Z","shell.execute_reply":"2023-08-10T10:16:59.689075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T10:16:59.691501Z","iopub.execute_input":"2023-08-10T10:16:59.692192Z","iopub.status.idle":"2023-08-10T10:16:59.709568Z","shell.execute_reply.started":"2023-08-10T10:16:59.692158Z","shell.execute_reply":"2023-08-10T10:16:59.708325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom transformers import pipeline\nfrom pprint import pprint\n\n# nlp = pipeline(\"text-classification\", model=\"cartesinus/xlm-r-base-amazon-massive-intent-label_smoothing\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T10:16:59.712191Z","iopub.execute_input":"2023-08-10T10:16:59.713583Z","iopub.status.idle":"2023-08-10T10:18:28.184871Z","shell.execute_reply.started":"2023-08-10T10:16:59.713545Z","shell.execute_reply":"2023-08-10T10:18:28.183769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(nlp(test_data.iloc[:1, 1].values[0])[0][\"label\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-10T10:18:28.186271Z","iopub.execute_input":"2023-08-10T10:18:28.186660Z","iopub.status.idle":"2023-08-10T10:18:28.363115Z","shell.execute_reply.started":"2023-08-10T10:18:28.186623Z","shell.execute_reply":"2023-08-10T10:18:28.361744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.iloc[4851:4852,1].values[0].encode('utf-8').decode('utf-8')","metadata":{"execution":{"iopub.status.busy":"2023-08-10T10:37:48.846338Z","iopub.execute_input":"2023-08-10T10:37:48.846711Z","iopub.status.idle":"2023-08-10T10:37:48.854802Z","shell.execute_reply.started":"2023-08-10T10:37:48.846681Z","shell.execute_reply":"2023-08-10T10:37:48.853449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\noutput_file = 'output.jsonl'\n\nwith open(output_file, 'w') as jsonl_file:\n    for index, row in test_data.iterrows():\n        id_value = row['indoml_id']\n        utterance = row['utt']\n        # Process the utterance using the model\n        result = nlp(utterance.encode('utf-8').decode('utf-8'))[0][\"label\"]\n        \n        # Create a dictionary for JSONL entry\n        json_entry = {'indoml_id': id_value, 'intent': result}\n        \n        # Write the JSON entry to the JSONL file\n        jsonl_file.write(json.dumps(json_entry) + '\\n')","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-10T10:37:48.857093Z","iopub.execute_input":"2023-08-10T10:37:48.857452Z","iopub.status.idle":"2023-08-10T15:13:22.407149Z","shell.execute_reply.started":"2023-08-10T10:37:48.857419Z","shell.execute_reply":"2023-08-10T15:13:22.406093Z"},"trusted":true},"execution_count":null,"outputs":[]}]}